"""é£ä¹¦å¤šç»´è¡¨æ ¼æ•°æ®åˆ†æè„šæœ¬"""

from __future__ import annotations

import asyncio
import sys
from pathlib import Path
from collections import Counter, defaultdict
from datetime import datetime
from typing import Any

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.config import get_settings
from src.storage.feishu_storage import FeishuStorage


def format_percentage(count: int, total: int) -> str:
    """æ ¼å¼åŒ–ç™¾åˆ†æ¯”"""
    if total == 0:
        return "0.0%"
    return f"{count / total * 100:.1f}%"


def normalize_field(value: Any) -> str:
    """æ ‡å‡†åŒ–å•å€¼å­—æ®µï¼ˆå­—ç¬¦ä¸²/åˆ—è¡¨/å¯¹è±¡ï¼‰è¿”å›å­—ç¬¦ä¸²ã€‚"""
    if value is None:
        return "Unknown"
    if isinstance(value, dict):
        return str(value.get("text") or value.get("link") or "Unknown")
    if isinstance(value, list):
        if not value:
            return "Unknown"
        first = value[0]
        if isinstance(first, dict):
            return str(first.get("text") or first.get("link") or "Unknown")
        return str(first)
    return str(value)


def normalize_domains(value: Any) -> list[str]:
    """æ ‡å‡†åŒ–ä»»åŠ¡é¢†åŸŸï¼Œè¿”å›åˆ—è¡¨ä¾¿äºç»Ÿè®¡ã€‚"""
    if value is None:
        return ["Unknown"]
    if isinstance(value, list):
        vals = [normalize_field(v) for v in value if v]
        return vals or ["Unknown"]
    return [normalize_field(value)]


def analyze_records(records: list[dict[str, Any]]) -> dict[str, Any]:
    """åˆ†æé£ä¹¦è®°å½•"""

    total = len(records)
    if total == 0:
        return {"error": "æ— è®°å½•"}

    # 1. æŒ‰æ¥æºç»Ÿè®¡
    source_counts = Counter(r.get("source") or "Unknown" for r in records)

    # 2. æŒ‰ä»»åŠ¡é¢†åŸŸç»Ÿè®¡ï¼ˆå±•å¼€å¤šå€¼ï¼‰
    task_domain_counts = Counter()
    for r in records:
        domains = normalize_domains(r.get("task_domain"))
        task_domain_counts.update(domains)

    # 3. è¯„åˆ†åˆ†å¸ƒ
    score_buckets = {"ä¼˜ç§€(â‰¥8)": 0, "è‰¯å¥½(7-8)": 0, "åˆæ ¼(6-7)": 0, "ä½åˆ†(<6)": 0, "ç¼ºå¤±": 0}
    scores = []
    for r in records:
        score = r.get("total_score")
        if score is None:
            score_buckets["ç¼ºå¤±"] += 1
        elif score >= 8:
            score_buckets["ä¼˜ç§€(â‰¥8)"] += 1
            scores.append(score)
        elif score >= 7:
            score_buckets["è‰¯å¥½(7-8)"] += 1
            scores.append(score)
        elif score >= 6:
            score_buckets["åˆæ ¼(6-7)"] += 1
            scores.append(score)
        else:
            score_buckets["ä½åˆ†(<6)"] += 1
            scores.append(score)

    avg_score = sum(scores) / len(scores) if scores else 0
    min_score = min(scores) if scores else 0
    max_score = max(scores) if scores else 0

    # 4. å‘å¸ƒæ—¶é—´åˆ†å¸ƒ
    now = datetime.now()
    time_buckets = {
        "æœ€è¿‘7å¤©": 0,
        "8-30å¤©": 0,
        "31-90å¤©": 0,
        "91-180å¤©": 0,
        "180å¤©ä»¥ä¸Š": 0,
        "ç¼ºå¤±": 0,
    }
    for r in records:
        pub_date_raw = r.get("publish_date")
        if not pub_date_raw:
            time_buckets["ç¼ºå¤±"] += 1
        else:
            # è§£ææ—¥æœŸå­—ç¬¦ä¸²
            try:
                if isinstance(pub_date_raw, str):
                    pub_date = datetime.fromisoformat(pub_date_raw.replace("Z", "+00:00"))
                elif isinstance(pub_date_raw, datetime):
                    pub_date = pub_date_raw
                else:
                    time_buckets["ç¼ºå¤±"] += 1
                    continue
                
                days_ago = (now - pub_date).days
                if days_ago <= 7:
                    time_buckets["æœ€è¿‘7å¤©"] += 1
                elif days_ago <= 30:
                    time_buckets["8-30å¤©"] += 1
                elif days_ago <= 90:
                    time_buckets["31-90å¤©"] += 1
                elif days_ago <= 180:
                    time_buckets["91-180å¤©"] += 1
                else:
                    time_buckets["180å¤©ä»¥ä¸Š"] += 1
            except Exception:
                time_buckets["ç¼ºå¤±"] += 1

    # 5. ç¼ºå¤±å­—æ®µç»Ÿè®¡
    missing_fields = defaultdict(int)
    for r in records:
        # title
        title_val = normalize_field(r.get("title"))
        if title_val == "Unknown":
            missing_fields["title"] += 1
        # source
        if not r.get("source"):
            missing_fields["source"] += 1
        # task_domain
        task_val = normalize_field(r.get("task_domain"))
        if task_val == "Unknown":
            missing_fields["task_domain"] += 1
        # total_score
        if r.get("total_score") is None:
            missing_fields["total_score"] += 1
        # publish_date
        if not r.get("publish_date"):
            missing_fields["publish_date"] += 1

    # 6. é‡å¤æ ‡é¢˜æ£€æµ‹
    titles = [normalize_field(r.get("title")) for r in records]
    title_counts = Counter(t for t in titles if t != "Unknown")
    duplicates = {title: count for title, count in title_counts.items() if count > 1}

    # 7. æ¥æº Ã— ä»»åŠ¡é¢†åŸŸäº¤å‰åˆ†æ
    source_task_matrix = defaultdict(lambda: defaultdict(int))
    for r in records:
        source = r.get("source") or "Unknown"
        task = normalize_field(r.get("task_domain"))
        source_task_matrix[source][task] += 1

    return {
        "total": total,
        "source_counts": dict(source_counts),
        "task_domain_counts": dict(task_domain_counts),
        "score_buckets": score_buckets,
        "score_stats": {
            "avg": avg_score,
            "min": min_score,
            "max": max_score,
            "æœ‰è¯„åˆ†æ•°é‡": len(scores),
        },
        "time_buckets": time_buckets,
        "missing_fields": dict(missing_fields),
        "duplicates": duplicates,
        "source_task_matrix": {k: dict(v) for k, v in source_task_matrix.items()},
    }


def print_report(stats: dict[str, Any]) -> None:
    """æ‰“å°åˆ†ææŠ¥å‘Š"""

    print("\n" + "=" * 80)
    print("é£ä¹¦å¤šç»´è¡¨æ ¼æ•°æ®åˆ†ææŠ¥å‘Š")
    print("=" * 80)

    total = stats["total"]
    print(f"\nğŸ“Š æ€»è®°å½•æ•°: {total}")

    # 1. æ¥æºåˆ†å¸ƒ
    print(f"\n{'=' * 80}")
    print("1ï¸âƒ£ æŒ‰æ¥æºåˆ†å¸ƒ")
    print("-" * 80)
    for source, count in sorted(stats["source_counts"].items(), key=lambda x: x[1], reverse=True):
        pct = format_percentage(count, total)
        print(f"   {source:20s}: {count:4d} æ¡ ({pct})")

    # 2. ä»»åŠ¡é¢†åŸŸåˆ†å¸ƒ
    print(f"\n{'=' * 80}")
    print("2ï¸âƒ£ æŒ‰ä»»åŠ¡é¢†åŸŸåˆ†å¸ƒ")
    print("-" * 80)
    for task, count in sorted(stats["task_domain_counts"].items(), key=lambda x: x[1], reverse=True):
        pct = format_percentage(count, total)
        print(f"   {task:20s}: {count:4d} æ¡ ({pct})")

    # 3. è¯„åˆ†åˆ†å¸ƒ
    print(f"\n{'=' * 80}")
    print("3ï¸âƒ£ è¯„åˆ†è´¨é‡åˆ†å¸ƒ")
    print("-" * 80)
    for bucket, count in stats["score_buckets"].items():
        pct = format_percentage(count, total)
        print(f"   {bucket:15s}: {count:4d} æ¡ ({pct})")

    score_stats = stats["score_stats"]
    print(f"\n   è¯„åˆ†ç»Ÿè®¡:")
    print(f"   - å¹³å‡åˆ†: {score_stats['avg']:.2f}")
    print(f"   - æœ€é«˜åˆ†: {score_stats['max']:.2f}")
    print(f"   - æœ€ä½åˆ†: {score_stats['min']:.2f}")
    print(f"   - æœ‰è¯„åˆ†æ•°é‡: {score_stats['æœ‰è¯„åˆ†æ•°é‡']}/{total}")

    # 4. å‘å¸ƒæ—¶é—´åˆ†å¸ƒ
    print(f"\n{'=' * 80}")
    print("4ï¸âƒ£ å‘å¸ƒæ—¶é—´æ–°é²œåº¦")
    print("-" * 80)
    for bucket, count in stats["time_buckets"].items():
        pct = format_percentage(count, total)
        print(f"   {bucket:15s}: {count:4d} æ¡ ({pct})")

    # 5. æ•°æ®è´¨é‡é—®é¢˜
    print(f"\n{'=' * 80}")
    print("5ï¸âƒ£ æ•°æ®è´¨é‡é—®é¢˜")
    print("-" * 80)
    missing = stats["missing_fields"]
    if missing:
        print("   ç¼ºå¤±å­—æ®µç»Ÿè®¡:")
        for field, count in sorted(missing.items(), key=lambda x: x[1], reverse=True):
            pct = format_percentage(count, total)
            print(f"   - {field:20s}: {count:4d} æ¡ç¼ºå¤± ({pct})")
    else:
        print("   âœ… æ— ç¼ºå¤±å­—æ®µ")

    duplicates = stats["duplicates"]
    if duplicates:
        print(f"\n   âš ï¸ é‡å¤æ ‡é¢˜: {len(duplicates)} ä¸ª")
        print(f"   å‰5ä¸ªé‡å¤æœ€å¤šçš„:")
        for title, count in sorted(duplicates.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"   - {title[:60]}...: {count} æ¬¡")
    else:
        print("\n   âœ… æ— é‡å¤æ ‡é¢˜")

    # 6. æ¥æº Ã— ä»»åŠ¡é¢†åŸŸäº¤å‰åˆ†æ
    print(f"\n{'=' * 80}")
    print("6ï¸âƒ£ æ¥æº Ã— ä»»åŠ¡é¢†åŸŸäº¤å‰åˆ†æï¼ˆTop 5æ¥æºï¼‰")
    print("-" * 80)
    source_task = stats["source_task_matrix"]
    top_sources = sorted(stats["source_counts"].items(), key=lambda x: x[1], reverse=True)[:5]

    for source, _ in top_sources:
        tasks = source_task.get(source, {})
        if tasks:
            print(f"\n   {source}:")
            for task, count in sorted(tasks.items(), key=lambda x: x[1], reverse=True):
                print(f"      - {task:20s}: {count:3d} æ¡")

    print(f"\n{'=' * 80}")


async def main() -> None:
    print("æ­£åœ¨è¯»å–é£ä¹¦å¤šç»´è¡¨æ ¼æ•°æ®...")
    settings = get_settings()
    storage = FeishuStorage(settings)
    records = await storage.read_brief_records()

    if not records:
        print("âš ï¸ æœªè¯»å–åˆ°ä»»ä½•è®°å½•")
        return

    print(f"âœ… æˆåŠŸè¯»å– {len(records)} æ¡è®°å½•\n")
    stats = analyze_records(records)
    print_report(stats)
    print("\nåˆ†æå®Œæˆï¼\n")


if __name__ == "__main__":
    asyncio.run(main())
