"""æµ‹è¯•LLMè¯„åˆ†çš„äººæ€§åŒ–å†™ä½œé£æ ¼

éªŒè¯Codex Phaseäººæ€§åŒ–ä¼˜åŒ–çš„æ•ˆæœï¼š
1. overall_reasoning â‰¥ 200å­—ç¬¦ï¼ˆä»50æå‡è‡³200ï¼‰
2. å†™ä½œé£æ ¼ï¼šMarkdownæ ¼å¼ã€âœ…/âš ï¸/ğŸ’¡ç¬¦å·ã€ç¦æ­¢ã€ã€‘ç¬¦å·
3. æ¨ç†ç»“æ„ï¼šçŸ­æ®µè½ã€åŠ ç²—å…³é”®æ•°æ®ã€ç»“å°¾ç»™å‡º"â­ æ˜¯å¦çº³å…¥"ç»“è®º
"""

import asyncio
import sys
from datetime import datetime
from pathlib import Path

sys.path.append(str(Path(__file__).resolve().parent.parent))

from src.models import RawCandidate
from src.scorer import LLMScorer


async def test_writing_style():
    """æµ‹è¯•LLMè¯„åˆ†çš„å†™ä½œé£æ ¼ä¼˜åŒ–"""

    # ä½¿ç”¨å·²çŸ¥çš„é«˜è´¨é‡è®ºæ–‡ï¼ˆSWE-benchï¼‰
    test_paper = RawCandidate(
        title="SWE-bench: Can Language Models Resolve Real-World GitHub Issues?",
        url="https://arxiv.org/abs/2310.06770",
        source="arxiv",
        abstract="We introduce SWE-bench, an evaluation framework consisting of 2,294 software engineering problems drawn from real GitHub issues and corresponding pull requests across 12 popular Python repositories.",
        paper_url="https://arxiv.org/abs/2310.06770",
        publish_date=datetime(2023, 10, 10),
        github_stars=1200,
        github_url="https://github.com/princeton-nlp/SWE-bench",
    )

    print("=" * 80)
    print("æµ‹è¯•ï¼šLLMè¯„åˆ†äººæ€§åŒ–å†™ä½œé£æ ¼")
    print("=" * 80)
    print(f"\næµ‹è¯•è®ºæ–‡: {test_paper.title}")
    print(f"arXiv URL: {test_paper.paper_url}")

    # LLMè¯„åˆ†
    print("\n" + "-" * 80)
    print("æ‰§è¡ŒLLMè¯„åˆ†...")
    print("-" * 80)

    async with LLMScorer() as scorer:
        try:
            scored = await scorer.score(test_paper)

            print("\nâœ… LLMè¯„åˆ†å®Œæˆ\n")

            # éªŒè¯1: overall_reasoningé•¿åº¦
            print("=" * 80)
            print("ã€éªŒè¯1ã€‘overall_reasoningé•¿åº¦è¦æ±‚ï¼ˆâ‰¥200å­—ç¬¦ï¼‰")
            print("=" * 80)
            overall_len = len(scored.overall_reasoning)
            print(f"\nå®é™…é•¿åº¦: {overall_len} å­—ç¬¦")
            print(f"è¦æ±‚é˜ˆå€¼: 200 å­—ç¬¦")
            if overall_len >= 200:
                print(f"âœ… PASS - é•¿åº¦è¾¾æ ‡ ({overall_len} â‰¥ 200)")
            else:
                print(f"âŒ FAIL - é•¿åº¦ä¸è¶³ ({overall_len} < 200)")

            # éªŒè¯2: å†™ä½œé£æ ¼ç‰¹å¾
            print("\n" + "=" * 80)
            print("ã€éªŒè¯2ã€‘å†™ä½œé£æ ¼è¦æ±‚")
            print("=" * 80)

            # æ£€æŸ¥ç¦æ­¢çš„ã€ã€‘ç¬¦å·
            has_brackets = "ã€" in scored.overall_reasoning or "ã€‘" in scored.overall_reasoning
            print(f"\nâœ… æ— ã€ã€‘ç¬¦å·: {not has_brackets}")
            if has_brackets:
                print("  âš ï¸  WARNING - å‘ç°ç¦æ­¢çš„ã€ã€‘ç¬¦å·")

            # æ£€æŸ¥æ¨èçš„ç¬¦å·ï¼ˆâœ…/âš ï¸/ğŸ’¡/â­ï¼‰
            has_checkmark = "âœ…" in scored.overall_reasoning
            has_warning = "âš ï¸" in scored.overall_reasoning
            has_bulb = "ğŸ’¡" in scored.overall_reasoning
            has_star = "â­" in scored.overall_reasoning
            emoji_count = sum([has_checkmark, has_warning, has_bulb, has_star])
            print(f"âœ… ä½¿ç”¨æ¨èç¬¦å·: {emoji_count}/4 (âœ…:{has_checkmark} âš ï¸:{has_warning} ğŸ’¡:{has_bulb} â­:{has_star})")

            # æ£€æŸ¥Markdownæ ¼å¼ï¼ˆåˆ—è¡¨ã€åŠ ç²—ï¼‰
            has_list = "-" in scored.overall_reasoning or "*" in scored.overall_reasoning
            has_bold = "**" in scored.overall_reasoning
            print(f"âœ… Markdownåˆ—è¡¨: {has_list}")
            print(f"âœ… åŠ ç²—å…³é”®æ•°æ®: {has_bold}")

            # éªŒè¯3: æ¨ç†å†…å®¹å±•ç¤º
            print("\n" + "=" * 80)
            print("ã€éªŒè¯3ã€‘overall_reasoningå®Œæ•´å†…å®¹")
            print("=" * 80)
            print(f"\n{scored.overall_reasoning}")

            # éªŒè¯4: å…¶ä»–æ¨ç†å­—æ®µé•¿åº¦
            print("\n" + "=" * 80)
            print("ã€éªŒè¯4ã€‘å…¶ä»–æ¨ç†å­—æ®µé•¿åº¦")
            print("=" * 80)
            reasoning_fields = {
                "activity_reasoning": scored.activity_reasoning,
                "reproducibility_reasoning": scored.reproducibility_reasoning,
                "license_reasoning": scored.license_reasoning,
                "novelty_reasoning": scored.novelty_reasoning,
                "relevance_reasoning": scored.relevance_reasoning,
            }

            print("\nå„ç»´åº¦æ¨ç†é•¿åº¦:")
            for field_name, reasoning_text in reasoning_fields.items():
                length = len(reasoning_text)
                status = "âœ…" if length >= 150 else "âš ï¸"
                print(f"  {status} {field_name:30s}: {length:4d} chars (â‰¥150)")

            # æ€»æ¨ç†é•¿åº¦
            total_reasoning = sum(len(text) for text in reasoning_fields.values()) + overall_len
            print(f"\næ€»æ¨ç†é•¿åº¦: {total_reasoning} chars")
            if total_reasoning >= 1200:
                print(f"âœ… PASS - æ€»æ¨ç†é•¿åº¦è¾¾æ ‡ ({total_reasoning} â‰¥ 1200)")
            else:
                print(f"âš ï¸  WARNING - æ€»æ¨ç†é•¿åº¦ä¸è¶³ ({total_reasoning} < 1200)")

            # éªŒè¯5: è¯„åˆ†ç»“æœ
            print("\n" + "=" * 80)
            print("ã€éªŒè¯5ã€‘è¯„åˆ†ç»“æœ")
            print("=" * 80)
            print(f"\n  activity_score:        {scored.activity_score:.1f}/10")
            print(f"  reproducibility_score: {scored.reproducibility_score:.1f}/10")
            print(f"  license_score:         {scored.license_score:.1f}/10")
            print(f"  novelty_score:         {scored.novelty_score:.1f}/10")
            print(f"  relevance_score:       {scored.relevance_score:.1f}/10")
            avg_score = (
                scored.activity_score
                + scored.reproducibility_score
                + scored.license_score
                + scored.novelty_score
                + scored.relevance_score
            ) / 5
            print(f"\n  å¹³å‡åˆ†: {avg_score:.2f}/10")

            # æœ€ç»ˆæ€»ç»“
            print("\n" + "=" * 80)
            print("ã€æµ‹è¯•æ€»ç»“ã€‘")
            print("=" * 80)
            checks = [
                ("overall_reasoningé•¿åº¦â‰¥200", overall_len >= 200),
                ("æ— ç¦æ­¢çš„ã€ã€‘ç¬¦å·", not has_brackets),
                ("ä½¿ç”¨æ¨èç¬¦å·(â‰¥1ä¸ª)", emoji_count >= 1),
                ("Markdownæ ¼å¼", has_list and has_bold),
                ("æ€»æ¨ç†é•¿åº¦â‰¥1200", total_reasoning >= 1200),
            ]

            pass_count = sum(1 for _, passed in checks if passed)
            print(f"\né€šè¿‡æ£€æŸ¥: {pass_count}/{len(checks)}")
            for check_name, passed in checks:
                status = "âœ… PASS" if passed else "âŒ FAIL"
                print(f"  {status} - {check_name}")

            if pass_count == len(checks):
                print("\nğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼å†™ä½œé£æ ¼ä¼˜åŒ–æˆåŠŸï¼")
            else:
                print(f"\nâš ï¸  éƒ¨åˆ†æ£€æŸ¥æœªé€šè¿‡ ({pass_count}/{len(checks)})")

        except Exception as e:
            print(f"\nâŒ LLMè¯„åˆ†å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            return

    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(test_writing_style())
