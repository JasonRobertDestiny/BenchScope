"""éªŒè¯æœ€è¿‘é‡‡é›†æ•°æ®çš„æ–°é²œåº¦ï¼ˆåŸºäºæ—¥å¿—åˆ†æï¼‰"""

import re
import sys
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, List, TypedDict, cast

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))


class LogStats(TypedDict, total=False):
    """æ—¥å¿—ç»Ÿè®¡å­—æ®µå®šä¹‰"""

    arxiv_count: int
    github_count: int
    hf_count: int
    prefilter_input: int
    prefilter_output: int
    prefilter_rate: float
    score_success: int
    score_total: int


class KeywordStats(TypedDict, total=False):
    """å…³é”®è¯è¦†ç›–ç»Ÿè®¡å­—æ®µå®šä¹‰"""

    total_keywords: int
    has_reasoning: bool
    has_multimodal: bool
    has_knowledge: bool
    sample_keywords: List[str]


def parse_log_file(log_file: Path) -> LogStats:
    """è§£ææ—¥å¿—æ–‡ä»¶ï¼Œæå–é‡‡é›†æ•°æ®"""

    with open(log_file, "r", encoding="utf-8") as f:
        content = f.read()

    # æå–é‡‡é›†ç»Ÿè®¡
    arxiv_match = re.search(r"ArxivCollector: (\d+)æ¡", content)
    github_match = re.search(r"GitHubCollector: (\d+)æ¡", content)
    hf_match = re.search(r"HuggingFaceCollector: (\d+)æ¡", content)

    # æå–é¢„ç­›é€‰ç»Ÿè®¡
    prefilter_match = re.search(
        r"é¢„ç­›é€‰å®Œæˆ,è¾“å…¥(\d+)æ¡,è¾“å‡º(\d+)æ¡,è¿‡æ»¤ç‡([\d.]+)%",
        content,
    )

    # æå–è¯„åˆ†ç»Ÿè®¡
    score_match = re.search(r"æ‰¹é‡è¯„åˆ†å®Œæˆ: æˆåŠŸ(\d+)æ¡/å…±(\d+)æ¡", content)

    stats: LogStats = {
        "arxiv_count": int(arxiv_match.group(1)) if arxiv_match else 0,
        "github_count": int(github_match.group(1)) if github_match else 0,
        "hf_count": int(hf_match.group(1)) if hf_match else 0,
    }

    if prefilter_match:
        stats["prefilter_input"] = int(prefilter_match.group(1))
        stats["prefilter_output"] = int(prefilter_match.group(2))
        stats["prefilter_rate"] = float(prefilter_match.group(3))

    if score_match:
        stats["score_success"] = int(score_match.group(1))
        stats["score_total"] = int(score_match.group(2))

    return stats


def analyze_github_query_strategy():
    """åˆ†æGitHubé‡‡é›†å™¨çš„æŸ¥è¯¢ç­–ç•¥"""

    github_collector_file = Path("src/collectors/github_collector.py")

    with open(github_collector_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æ£€æŸ¥ä½¿ç”¨çš„æ˜¯ pushed:>= è¿˜æ˜¯ created:>=
    if 'pushed:>=' in content:
        strategy = "pushed:>= (æœ€åæ›´æ–°æ—¶é—´)"
        issue = "âŒ ä¼šé‡‡é›†è€é¡¹ç›®çš„æ–°commit"
    elif 'created:>=' in content:
        strategy = "created:>= (é¦–æ¬¡åˆ›å»ºæ—¶é—´)"
        issue = "âœ… åªé‡‡é›†æ–°åˆ›å»ºçš„é¡¹ç›®"
    else:
        strategy = "æœªçŸ¥"
        issue = "âš ï¸ æ— æ³•ç¡®å®šç­–ç•¥"

    # æ£€æŸ¥æ—¶é—´çª—å£
    lookback_match = re.search(r'lookback_days.*=.*(\d+)', content)
    lookback_days = int(lookback_match.group(1)) if lookback_match else "æœªçŸ¥"

    return {
        'strategy': strategy,
        'issue': issue,
        'lookback_days': lookback_days,
    }


def analyze_prefilter_keywords() -> KeywordStats:
    """åˆ†æé¢„ç­›é€‰å…³é”®è¯è¦†ç›–"""

    constants_file = Path("src/common/constants.py")

    with open(constants_file, "r", encoding="utf-8") as f:
        content = f.read()

    # æå–å…³é”®è¯åˆ—è¡¨
    keywords_match = re.search(
        r"PREFILTER_REQUIRED_KEYWORDS.*?\[(.*?)\]",
        content,
        re.DOTALL,
    )

    if keywords_match:
        keywords_text = keywords_match.group(1)
        # ç»Ÿè®¡å…³é”®è¯æ•°é‡ï¼ˆå»é™¤æ³¨é‡Šï¼‰
        keywords = [
            line.strip().strip('"').strip("'").rstrip(",")
            for line in keywords_text.split("\n")
            if line.strip() and not line.strip().startswith("#")
        ]
        keywords = [k for k in keywords if k]

        # æ£€æŸ¥æ–°å¢ç±»åˆ«è¦†ç›–æƒ…å†µ
        has_reasoning = any(
            "reasoning" in k.lower() or "math" in k.lower() for k in keywords
        )
        has_multimodal = any(
            "multimodal" in k.lower() or "vision" in k.lower() for k in keywords
        )
        has_knowledge = any(
            "knowledge" in k.lower() or "qa" in k.lower() for k in keywords
        )

        return {
            "total_keywords": len(keywords),
            "has_reasoning": has_reasoning,
            "has_multimodal": has_multimodal,
            "has_knowledge": has_knowledge,
            "sample_keywords": keywords[:10],
        }

    return {"total_keywords": 0}


def main():
    """ä¸»éªŒè¯æµç¨‹"""

    print(f"\n{'='*80}")
    print(f"BenchScopeæ•°æ®æ–°é²œåº¦éªŒè¯æŠ¥å‘Š")
    print(f"{'='*80}\n")

    # 1. åˆ†ææœ€è¿‘çš„æ—¥å¿—
    log_dir = Path("logs")
    recent_logs = sorted(log_dir.glob("*.log"), reverse=True)[:3]

    print(f"ğŸ“Š æœ€è¿‘3æ¬¡è¿è¡Œç»Ÿè®¡:\n")

    for i, log_file in enumerate(recent_logs, 1):
        stats = parse_log_file(log_file)
        date = log_file.stem

        print(f"{i}. {date}")
        print(f"   é‡‡é›†: arXiv={stats.get('arxiv_count', 0)} | "
              f"GitHub={stats.get('github_count', 0)} | "
              f"HF={stats.get('hf_count', 0)}")

        if 'prefilter_output' in stats:
            pre_out = stats.get('prefilter_output', 0)
            pre_in = stats.get('prefilter_input', 0)
            pre_rate = stats.get('prefilter_rate', 0.0)
            print(f"   é¢„ç­›é€‰: {pre_out}/{pre_in} (è¿‡æ»¤ç‡{pre_rate:.1f}%)")

        if 'score_success' in stats:
            score_succ = stats.get('score_success', 0)
            score_total = stats.get('score_total', 0)
            print(f"   è¯„åˆ†: {score_succ}/{score_total}")
        print()

    # 2. åˆ†æGitHubæŸ¥è¯¢ç­–ç•¥
    print(f"\n{'='*80}")
    print(f"ğŸ” GitHubé‡‡é›†å™¨é…ç½®åˆ†æ\n")
    print(f"{'='*80}\n")

    github_config = analyze_github_query_strategy()
    print(f"æŸ¥è¯¢ç­–ç•¥: {github_config['strategy']}")
    print(f"æ—¶é—´çª—å£: {github_config['lookback_days']}å¤©")
    print(f"å½±å“: {github_config['issue']}\n")

    # 3. åˆ†æé¢„ç­›é€‰å…³é”®è¯
    print(f"{'='*80}")
    print(f"ğŸ”‘ é¢„ç­›é€‰å…³é”®è¯åˆ†æ\n")
    print(f"{'='*80}\n")

    keywords_config = analyze_prefilter_keywords()
    print(f"å…³é”®è¯æ€»æ•°: {keywords_config.get('total_keywords', 0)}")
    print(f"åŒ…å«Reasoningç±»: {'âœ…' if keywords_config.get('has_reasoning') else 'âŒ'}")
    print(f"åŒ…å«Multimodalç±»: {'âœ…' if keywords_config.get('has_multimodal') else 'âŒ'}")
    print(f"åŒ…å«Knowledgeç±»: {'âœ…' if keywords_config.get('has_knowledge') else 'âŒ'}\n")

    sample_keywords = cast(List[str], keywords_config.get("sample_keywords", []))
    if sample_keywords:
        print(f"ç¤ºä¾‹å…³é”®è¯: {', '.join(sample_keywords[:5])}\n")

    # 4. ç»¼åˆè¯Šæ–­
    print(f"{'='*80}")
    print(f"ğŸ¯ ç»¼åˆè¯Šæ–­\n")
    print(f"{'='*80}\n")

    issues = []
    filter_rate = 0.0  # é»˜è®¤0ï¼Œé¿å…æœªå®šä¹‰å¼•ç”¨

    # æ£€æŸ¥è¿‡æ»¤ç‡
    if recent_logs:
        latest_stats = parse_log_file(recent_logs[0])
        filter_rate = float(latest_stats.get('prefilter_rate', 0))

        if filter_rate > 80:
            issues.append(f"âŒ è¿‡æ»¤ç‡è¿‡é«˜({filter_rate:.1f}%)ï¼Œå¯èƒ½æ¼æ‰æ–°å­¦æœ¯å·¥ä½œ")
        elif filter_rate < 50:
            issues.append(f"âœ… è¿‡æ»¤ç‡æ­£å¸¸({filter_rate:.1f}%)")
        else:
            issues.append(f"âš ï¸ è¿‡æ»¤ç‡åé«˜({filter_rate:.1f}%)ï¼Œå»ºè®®ä¼˜åŒ–")

    # æ£€æŸ¥GitHubç­–ç•¥
    if 'pushed:>=' in github_config['strategy']:
        issues.append("âŒ GitHubä½¿ç”¨pushed:>=ï¼Œä¼šé‡‡é›†swebenchç­‰è€é¡¹ç›®")
    elif 'created:>=' in github_config['strategy']:
        issues.append("âœ… GitHubä½¿ç”¨created:>=ï¼Œåªé‡‡é›†æ–°é¡¹ç›®")

    # æ£€æŸ¥å…³é”®è¯è¦†ç›–
    if keywords_config.get('total_keywords', 0) < 50:
        issues.append(f"âŒ å…³é”®è¯è¿‡å°‘({keywords_config.get('total_keywords')}ä¸ª)ï¼Œè¦†ç›–ä¸è¶³")
    elif keywords_config.get('total_keywords', 0) >= 70:
        issues.append(f"âœ… å…³é”®è¯å……è¶³({keywords_config.get('total_keywords')}ä¸ª)")

    for issue in issues:
        print(issue)

    print(f"\n{'='*80}")
    print(f"ğŸ“‹ å»ºè®®æªæ–½\n")
    print(f"{'='*80}\n")

    if filter_rate > 80:
        print("1. æ‰©å……å…³é”®è¯åˆ—è¡¨ï¼ˆå¢åŠ reasoning/multimodal/knowledgeç±»åˆ«ï¼‰")
        print("2. å°†arXivåŠ å…¥TRUSTED_SOURCESç™½åå•ï¼Œé¿å…é‡å¤è¿‡æ»¤")

    if 'pushed:>=' in github_config['strategy']:
        print("3. ä¿®æ”¹GitHubæŸ¥è¯¢ç­–ç•¥ï¼špushed:>= â†’ created:>=")
        print("   æˆ–ä½¿ç”¨æ··åˆç­–ç•¥ï¼šæ–°é¡¹ç›®(created) + æ´»è·ƒé¡¹ç›®(pushed + created>6æœˆ)")

    print(f"\nè¯¦ç»†ä¼˜åŒ–æ–¹æ¡ˆè§: .claude/specs/benchmark-intelligence-agent/CODEX-FILTER-OPTIMIZATION.md\n")


if __name__ == "__main__":
    main()
