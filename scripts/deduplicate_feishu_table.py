"""å»é‡é£ä¹¦Bitableæ•°æ®ï¼ˆä¿ç•™æ¯ä¸ªURLçš„æœ€æ–°è®°å½•ï¼‰

ç”¨æ³•: python scripts/deduplicate_feishu_table.py
"""
import asyncio
import sys
from collections import defaultdict
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import httpx
from src.storage.feishu_storage import FeishuStorage


async def main():
    storage = FeishuStorage()
    await storage._ensure_access_token()

    # 1. è·å–æ‰€æœ‰è®°å½•
    all_records = []
    page_token = None

    async with httpx.AsyncClient(timeout=10) as client:
        while True:
            url = f"{storage.base_url}/bitable/v1/apps/{storage.settings.feishu.bitable_app_token}/tables/{storage.settings.feishu.bitable_table_id}/records/search"
            payload = {"page_size": 500}
            if page_token:
                payload["page_token"] = page_token

            resp = await client.post(url, headers=storage._auth_header(), json=payload)
            resp.raise_for_status()
            data = resp.json()

            if data.get("code") != 0:
                print(f"âŒ æŸ¥è¯¢å¤±è´¥: {data}")
                return

            items = data.get("data", {}).get("items", [])
            all_records.extend(items)

            if not data.get("data", {}).get("has_more", False):
                break
            page_token = data.get("data", {}).get("page_token")

    print(f"ğŸ“Š é£ä¹¦è¡¨æ ¼æ€»è®°å½•æ•°: {len(all_records)}")

    # 2. æŒ‰URLåˆ†ç»„
    url_to_records = defaultdict(list)
    url_field_name = storage.FIELD_MAPPING["url"]

    for record in all_records:
        fields = record.get("fields", {})
        url_obj = fields.get(url_field_name)

        url_value = None
        if isinstance(url_obj, dict):
            url_value = url_obj.get("link")
        elif isinstance(url_obj, str):
            url_value = url_obj

        if url_value:
            url_to_records[url_value].append({
                "record_id": record.get("record_id"),
                "created_time": record.get("created_time", 0),
            })

    # 3. æ‰¾å‡ºé‡å¤è®°å½•
    to_delete = []

    for url, records in url_to_records.items():
        if len(records) > 1:
            print(f"\nâš ï¸  URLé‡å¤{len(records)}æ¬¡: {url[:60]}...")
            records_sorted = sorted(records, key=lambda x: x["created_time"], reverse=True)
            for old_record in records_sorted[1:]:
                to_delete.append(old_record["record_id"])

    if not to_delete:
        print("\nâœ… æ— é‡å¤è®°å½•")
        return

    print(f"\nğŸ“‹ å°†åˆ é™¤{len(to_delete)}æ¡é‡å¤è®°å½•")
    confirm = input("ç¡®è®¤åˆ é™¤å—ï¼Ÿ(è¾“å…¥ 'yes' ç¡®è®¤): ")

    if confirm.lower() != "yes":
        print("âŒ æ“ä½œå·²å–æ¶ˆ")
        return

    # 4. æ‰¹é‡åˆ é™¤
    async with httpx.AsyncClient(timeout=10) as client:
        delete_url = f"{storage.base_url}/bitable/v1/apps/{storage.settings.feishu.bitable_app_token}/tables/{storage.settings.feishu.bitable_table_id}/records/batch_delete"

        for i in range(0, len(to_delete), 500):
            batch = to_delete[i : i + 500]
            delete_resp = await client.post(delete_url, headers=storage._auth_header(), json={"records": batch})
            delete_resp.raise_for_status()

            if delete_resp.json().get("code") != 0:
                print(f"âŒ åˆ é™¤å¤±è´¥: {delete_resp.json()}")
                return

            print(f"âœ… å·²åˆ é™¤{len(batch)}æ¡é‡å¤è®°å½•")

    print(f"\nğŸ‰ å»é‡å®Œæˆï¼ä¿ç•™{len(url_to_records)}æ¡å”¯ä¸€è®°å½•")


if __name__ == "__main__":
    asyncio.run(main())
