# Phase 7.2 å¼€å‘æŒ‡ä»¤ï¼šé£ä¹¦é›†æˆä¸æµ‹è¯•è¡¥å……

## æ‰§è¡Œè€…ï¼šCodex

## èƒŒæ™¯

Phase 7.1å·²å®Œæˆä¸‰åŸŸè¯„åˆ†æ¨¡å‹çš„æ ¸å¿ƒå®ç°ï¼ˆAgentCapabilityScores/RiskDomainScores/OperationalScoresï¼‰ï¼Œä½†é£ä¹¦å­˜å‚¨å’Œé€šçŸ¥æ¨¡å—å°šæœªåŒæ­¥æ›´æ–°ã€‚**å½“å‰ç”¨æˆ·æ— æ³•åœ¨é£ä¹¦ä¸­çœ‹åˆ°ä¸‰åŸŸè¯„åˆ†æ•°æ®ï¼Œå¯¼è‡´æ”¹è¿›å¯¹ä¸šåŠ¡ä¸å¯è§**ã€‚

## æ ¸å¿ƒé—®é¢˜

1. **é£ä¹¦å¤šç»´è¡¨ç¼ºå¤±å­—æ®µ**ï¼š14ä¸ªæ–°å­—æ®µï¼ˆcapability_scores 5ä¸ª + risk_scores 4ä¸ª + æ±‡æ€»å­—æ®µ5ä¸ªï¼‰æœªå†™å…¥
2. **é£ä¹¦é€šçŸ¥å¡ç‰‡æœªå±•ç¤º**ï¼šæ¨é€æ¶ˆæ¯ä»ä½¿ç”¨æ—§ç‰ˆtotal_scoreï¼Œä¸‰åŸŸè¯„åˆ†ç»†èŠ‚å®Œå…¨ä¸å¯è§
3. **æµ‹è¯•è¦†ç›–ä¸è¶³**ï¼šå…³é”®é€»è¾‘ï¼ˆ_normalize_scoresã€priorityåˆ¤å®šã€SQLiteåºåˆ—åŒ–ï¼‰æ— å•å…ƒæµ‹è¯•

## ä»»åŠ¡ç›®æ ‡

æœ¬é˜¶æ®µå®Œæˆé£ä¹¦é›†æˆä¸æµ‹è¯•è¡¥å……ï¼Œç¡®ä¿ä¸‰åŸŸè¯„åˆ†å¯¹ä¸šåŠ¡å¯è§ï¼Œå¹¶é€šè¿‡æµ‹è¯•é˜²æ­¢åç»­å›é€€ã€‚

---

## Task 7.2.1ï¼šé£ä¹¦å¤šç»´è¡¨å­—æ®µæ˜ å°„

### éœ€æ±‚è¯´æ˜

å½“å‰`FeishuStorage`ä»…å†™å…¥æ—§ç‰ˆ5ç»´è¯„åˆ†ï¼ˆactivity_scoreç­‰ï¼‰ï¼Œéœ€æ–°å¢14ä¸ªå­—æ®µä»¥æ”¯æŒv2ä¸‰åŸŸè¯„åˆ†ã€‚

### æ–°å¢å­—æ®µæ¸…å•

**èƒ½åŠ›åŸŸï¼ˆ5ä¸ªï¼‰**ï¼š
- `planning_score` (æ•°å­—) - è§„åˆ’èƒ½åŠ›
- `tool_use_score` (æ•°å­—) - å·¥å…·ä½¿ç”¨èƒ½åŠ›
- `memory_score` (æ•°å­—) - è®°å¿†èƒ½åŠ›
- `collaboration_score` (æ•°å­—) - åä½œèƒ½åŠ›
- `reasoning_score` (æ•°å­—) - æ¨ç†èƒ½åŠ›

**é£é™©åŸŸï¼ˆ4ä¸ªï¼‰**ï¼š
- `security_score` (æ•°å­—) - å®‰å…¨æ€§
- `robustness_score` (æ•°å­—) - é²æ£’æ€§
- `hallucination_risk` (æ•°å­—) - å¹»è§‰é£é™©
- `compliance_score` (æ•°å­—) - åˆè§„æ€§

**æ±‡æ€»å­—æ®µï¼ˆ5ä¸ªï¼‰**ï¼š
- `capability_total` (æ•°å­—) - èƒ½åŠ›åŸŸæ€»åˆ†
- `risk_total` (æ•°å­—) - é£é™©åŸŸæ€»åˆ†
- `operational_total` (æ•°å­—) - è¿è¥åŸŸæ€»åˆ†
- `risk_level` (å•é€‰) - é£é™©ç­‰çº§ï¼ˆcritical/high/moderate/safe/unknownï¼‰
- `evaluation_version` (æ–‡æœ¬) - è¯„ä¼°ç‰ˆæœ¬ï¼ˆv1.0/v2.0ï¼‰

### å®æ–½æ­¥éª¤

#### Step 1ï¼šæ£€æŸ¥é£ä¹¦è¡¨æ ¼ç°æœ‰å­—æ®µ

```python
# æ–‡ä»¶ä½ç½®ï¼šscripts/check_feishu_fields.pyï¼ˆæ–°å»ºï¼‰

import asyncio
from src.storage.feishu_storage import FeishuStorage
from src.config import get_settings

async def check_fields():
    settings = get_settings()
    storage = FeishuStorage(settings=settings)

    # è°ƒç”¨é£ä¹¦APIè·å–è¡¨æ ¼å­—æ®µåˆ—è¡¨
    # å‚è€ƒï¼šhttps://open.feishu.cn/document/server-docs/docs/bitable-v1/app-table-field/list

    print("å½“å‰é£ä¹¦è¡¨æ ¼å­—æ®µï¼š")
    # TODO: åˆ—å‡ºæ‰€æœ‰å­—æ®µåç§°å’Œç±»å‹

if __name__ == "__main__":
    asyncio.run(check_fields())
```

#### Step 2ï¼šåˆ›å»ºé£ä¹¦å­—æ®µï¼ˆå¦‚ä¸å­˜åœ¨ï¼‰

```python
# æ–‡ä»¶ä½ç½®ï¼šscripts/create_feishu_fields_v2.pyï¼ˆæ–°å»ºï¼‰

import asyncio
from lark_oapi.api.bitable.v1 import *
from src.config import get_settings

FIELD_DEFINITIONS = [
    # èƒ½åŠ›åŸŸ
    {"field_name": "planning_score", "type": 2, "description": "è§„åˆ’èƒ½åŠ›è¯„åˆ†ï¼ˆ0-10ï¼‰"},
    {"field_name": "tool_use_score", "type": 2, "description": "å·¥å…·ä½¿ç”¨èƒ½åŠ›è¯„åˆ†ï¼ˆ0-10ï¼‰"},
    {"field_name": "memory_score", "type": 2, "description": "è®°å¿†èƒ½åŠ›è¯„åˆ†ï¼ˆ0-10ï¼‰"},
    {"field_name": "collaboration_score", "type": 2, "description": "åä½œèƒ½åŠ›è¯„åˆ†ï¼ˆ0-10ï¼‰"},
    {"field_name": "reasoning_score", "type": 2, "description": "æ¨ç†èƒ½åŠ›è¯„åˆ†ï¼ˆ0-10ï¼‰"},

    # é£é™©åŸŸ
    {"field_name": "security_score", "type": 2, "description": "å®‰å…¨æ€§è¯„åˆ†ï¼ˆ0-10ï¼‰"},
    {"field_name": "robustness_score", "type": 2, "description": "é²æ£’æ€§è¯„åˆ†ï¼ˆ0-10ï¼‰"},
    {"field_name": "hallucination_risk", "type": 2, "description": "å¹»è§‰é£é™©è¯„åˆ†ï¼ˆ0-10ï¼‰"},
    {"field_name": "compliance_score", "type": 2, "description": "åˆè§„æ€§è¯„åˆ†ï¼ˆ0-10ï¼‰"},

    # æ±‡æ€»å­—æ®µ
    {"field_name": "capability_total", "type": 2, "description": "èƒ½åŠ›åŸŸæ€»åˆ†"},
    {"field_name": "risk_total", "type": 2, "description": "é£é™©åŸŸæ€»åˆ†"},
    {"field_name": "operational_total", "type": 2, "description": "è¿è¥åŸŸæ€»åˆ†"},
    {"field_name": "risk_level", "type": 3, "description": "é£é™©ç­‰çº§",
     "options": ["critical", "high", "moderate", "safe", "unknown"]},
    {"field_name": "evaluation_version", "type": 1, "description": "è¯„ä¼°ç‰ˆæœ¬ï¼ˆv1.0/v2.0ï¼‰"},
]

async def create_fields():
    settings = get_settings()
    # TODO: ä½¿ç”¨lark_oapiåˆ›å»ºå­—æ®µ
    # å‚è€ƒï¼šhttps://open.feishu.cn/document/server-docs/docs/bitable-v1/app-table-field/create
    pass

if __name__ == "__main__":
    asyncio.run(create_fields())
```

**é‡è¦**ï¼š
- å­—æ®µç±»å‹ï¼š1=æ–‡æœ¬, 2=æ•°å­—, 3=å•é€‰
- å•é€‰å­—æ®µéœ€æå‰å®šä¹‰options
- å­—æ®µåˆ›å»ºåè·å–field_idï¼Œåç»­å†™å…¥æ—¶éœ€è¦

#### Step 3ï¼šæ›´æ–°FeishuStorageå†™å…¥é€»è¾‘

```python
# æ–‡ä»¶ä½ç½®ï¼šsrc/storage/feishu_storage.py

# æ‰¾åˆ° _build_record æ–¹æ³•ï¼ˆå½“å‰çº¦80-120è¡Œï¼‰

def _build_record(self, candidate: ScoredCandidate) -> dict:
    """æ„å»ºé£ä¹¦è¡¨æ ¼è®°å½•ï¼ˆåŒ…å«v2ä¸‰åŸŸè¯„åˆ†ï¼‰"""

    # åŸºç¡€å­—æ®µï¼ˆä¿æŒä¸å˜ï¼‰
    record = {
        "æ ‡é¢˜": candidate.title,
        "URL": candidate.url,
        # ... å…¶ä»–ç°æœ‰å­—æ®µ
    }

    # æ—§ç‰ˆ5ç»´è¯„åˆ†ï¼ˆä¿æŒå…¼å®¹ï¼‰
    record.update({
        "activity_score": candidate.activity_score,
        "reproducibility_score": candidate.reproducibility_score,
        "license_score": candidate.license_score,
        "novelty_score": candidate.novelty_score,
        "relevance_score": candidate.relevance_score,
    })

    # æ–°å¢ï¼šèƒ½åŠ›åŸŸè¯„åˆ†
    if candidate.capability_scores:
        record.update({
            "planning_score": candidate.capability_scores.planning_score,
            "tool_use_score": candidate.capability_scores.tool_use_score,
            "memory_score": candidate.capability_scores.memory_score,
            "collaboration_score": candidate.capability_scores.collaboration_score,
            "reasoning_score": candidate.capability_scores.reasoning_score,
        })

    # æ–°å¢ï¼šé£é™©åŸŸè¯„åˆ†
    if candidate.risk_scores:
        record.update({
            "security_score": candidate.risk_scores.security_score,
            "robustness_score": candidate.risk_scores.robustness_score,
            "hallucination_risk": candidate.risk_scores.hallucination_risk,
            "compliance_score": candidate.risk_scores.compliance_score,
        })

    # æ–°å¢ï¼šæ±‡æ€»å­—æ®µ
    record.update({
        "capability_total": candidate.capability_total,
        "risk_total": candidate.risk_total,
        "operational_total": candidate.operational_total,
        "risk_level": candidate.risk_level or "unknown",
        "evaluation_version": candidate.evaluation_version or "v1.0",
    })

    return record
```

**éªŒè¯è¦ç‚¹**ï¼š
- æ—§ç‰ˆå€™é€‰ï¼ˆæ— ä¸‰åŸŸè¯„åˆ†ï¼‰ï¼šä»…å†™å…¥operational_totalå’Œv1.0ç‰ˆæœ¬
- æ–°ç‰ˆå€™é€‰ï¼ˆæœ‰ä¸‰åŸŸè¯„åˆ†ï¼‰ï¼šå†™å…¥å®Œæ•´14ä¸ªå­—æ®µ
- å­—æ®µç¼ºå¤±æ—¶ä½¿ç”¨é»˜è®¤å€¼ï¼ˆ0.0æˆ–"unknown"ï¼‰

---

## Task 7.2.2ï¼šé£ä¹¦é€šçŸ¥å¡ç‰‡å±•ç¤ºä¸‰åŸŸè¯„åˆ†

### éœ€æ±‚è¯´æ˜

å½“å‰é£ä¹¦é€šçŸ¥ä»…æ˜¾ç¤ºtotal_scoreï¼Œç”¨æˆ·æ— æ³•çœ‹åˆ°ä¸‰åŸŸè¯„åˆ†ç»†èŠ‚ã€‚éœ€åœ¨å¡ç‰‡æ¶ˆæ¯ä¸­å±•ç¤ºèƒ½åŠ›/é£é™©/è¿è¥ä¸‰åŸŸå¾—åˆ†ã€‚

### è®¾è®¡æ–¹æ¡ˆ

**æ¨é€ç­–ç•¥**ï¼š
- Highä¼˜å…ˆçº§ï¼šå®Œæ•´ä¸‰åŸŸè¯„åˆ† + é£é™©ç­‰çº§ + reasoningæ‘˜è¦
- Mediumä¼˜å…ˆçº§ï¼šä¸‰åŸŸæ€»åˆ† + é£é™©ç­‰çº§
- Lowä¼˜å…ˆçº§ï¼šä»…æ€»åˆ†ï¼ˆä¿æŒç°æœ‰æ ¼å¼ï¼‰

### å®æ–½æ­¥éª¤

#### Step 1ï¼šæ›´æ–°_build_card_contentæ–¹æ³•

```python
# æ–‡ä»¶ä½ç½®ï¼šsrc/notifier/feishu_notifier.py

# æ‰¾åˆ° _build_card_content æ–¹æ³•ï¼ˆå½“å‰çº¦140-250è¡Œï¼‰

def _build_card_content(self, candidates: List[ScoredCandidate], priority: str) -> dict:
    """æ„å»ºé£ä¹¦å¡ç‰‡æ¶ˆæ¯ï¼ˆå±•ç¤ºä¸‰åŸŸè¯„åˆ†ï¼‰"""

    if priority == "high":
        return self._build_high_priority_card(candidates)
    elif priority == "medium":
        return self._build_medium_priority_card(candidates)
    else:
        return self._build_low_priority_card(candidates)

def _build_high_priority_card(self, candidates: List[ScoredCandidate]) -> dict:
    """é«˜ä¼˜å…ˆçº§å¡ç‰‡ï¼šå®Œæ•´ä¸‰åŸŸè¯„åˆ†"""

    elements = []

    for candidate in candidates:
        # æ ‡é¢˜
        elements.append({
            "tag": "div",
            "text": {
                "tag": "lark_md",
                "content": f"**{candidate.title[:constants.TITLE_TRUNCATE_MEDIUM]}**"
            }
        })

        # æ¥æºå’Œæ€»åˆ†
        source_name = constants.FEISHU_SOURCE_NAME_MAP.get(candidate.source, candidate.source)
        elements.append({
            "tag": "div",
            "fields": [
                {"is_short": True, "text": {"tag": "lark_md", "content": f"**æ¥æº**: {source_name}"}},
                {"is_short": True, "text": {"tag": "lark_md", "content": f"**æ€»åˆ†**: {candidate.total_score:.1f}/10"}},
            ]
        })

        # æ–°å¢ï¼šä¸‰åŸŸè¯„åˆ†
        if candidate.capability_scores and candidate.risk_scores:
            elements.append({
                "tag": "div",
                "text": {
                    "tag": "lark_md",
                    "content": (
                        f"**èƒ½åŠ›åŸŸ**: {candidate.capability_total:.1f} "
                        f"(è§„åˆ’{candidate.capability_scores.planning_score:.1f} "
                        f"å·¥å…·{candidate.capability_scores.tool_use_score:.1f} "
                        f"æ¨ç†{candidate.capability_scores.reasoning_score:.1f})\n"
                        f"**é£é™©åŸŸ**: {candidate.risk_total:.1f} "
                        f"(å®‰å…¨{candidate.risk_scores.security_score:.1f} "
                        f"é²æ£’{candidate.risk_scores.robustness_score:.1f})\n"
                        f"**è¿è¥åŸŸ**: {candidate.operational_total:.1f}"
                    )
                }
            })

            # æ–°å¢ï¼šé£é™©ç­‰çº§æ ‡è¯†
            risk_emoji = {
                "safe": "ğŸŸ¢",
                "moderate": "ğŸŸ¡",
                "high": "ğŸŸ ",
                "critical": "ğŸ”´",
                "unknown": "âšª"
            }
            risk_text = f"{risk_emoji.get(candidate.risk_level, 'âšª')} é£é™©ç­‰çº§: {candidate.risk_level}"
            elements.append({
                "tag": "div",
                "text": {"tag": "lark_md", "content": risk_text}
            })

        # Reasoningæ‘˜è¦ï¼ˆå‰200å­—ï¼‰
        if candidate.reasoning:
            reasoning_preview = candidate.reasoning[:200] + ("..." if len(candidate.reasoning) > 200 else "")
            elements.append({
                "tag": "div",
                "text": {
                    "tag": "lark_md",
                    "content": f"**è¯„åˆ†ä¾æ®**: {reasoning_preview}"
                }
            })

        # æŒ‰é’®
        elements.append({
            "tag": "action",
            "actions": [
                {
                    "tag": "button",
                    "text": {"tag": "plain_text", "content": "æŸ¥çœ‹è¯¦æƒ…"},
                    "type": "primary",
                    "url": candidate.url
                },
                {
                    "tag": "button",
                    "text": {"tag": "plain_text", "content": "é£ä¹¦å¤šç»´è¡¨"},
                    "url": constants.FEISHU_BENCH_TABLE_URL
                }
            ]
        })

        elements.append({"tag": "hr"})

    return {
        "config": {"wide_screen_mode": True},
        "header": {
            "template": "red",
            "title": {"tag": "plain_text", "content": f"ğŸ”¥ é«˜ä¼˜å…ˆçº§Benchmarkå€™é€‰ ({len(candidates)}æ¡)"}
        },
        "elements": elements
    }

def _build_medium_priority_card(self, candidates: List[ScoredCandidate]) -> dict:
    """ä¸­ä¼˜å…ˆçº§å¡ç‰‡ï¼šä¸‰åŸŸæ€»åˆ†"""

    elements = []

    for candidate in candidates:
        elements.append({
            "tag": "div",
            "text": {
                "tag": "lark_md",
                "content": f"**{candidate.title[:constants.TITLE_TRUNCATE_MEDIUM]}**"
            }
        })

        # ä¸‰åŸŸæ€»åˆ†ï¼ˆv2ï¼‰æˆ–æ—§ç‰ˆæ€»åˆ†ï¼ˆv1ï¼‰
        if candidate.capability_scores and candidate.risk_scores:
            score_text = (
                f"æ€»åˆ† {candidate.total_score:.1f}/10 = "
                f"èƒ½åŠ›{candidate.capability_total:.1f} + "
                f"é£é™©{candidate.risk_total:.1f} + "
                f"è¿è¥{candidate.operational_total:.1f}"
            )
            risk_label = f" | é£é™©: {candidate.risk_level}"
        else:
            score_text = f"æ€»åˆ† {candidate.total_score:.1f}/10"
            risk_label = ""

        elements.append({
            "tag": "div",
            "text": {
                "tag": "lark_md",
                "content": score_text + risk_label
            }
        })

        elements.append({
            "tag": "action",
            "actions": [{
                "tag": "button",
                "text": {"tag": "plain_text", "content": "æŸ¥çœ‹è¯¦æƒ…"},
                "url": candidate.url
            }]
        })

        elements.append({"tag": "hr"})

    return {
        "config": {"wide_screen_mode": True},
        "header": {
            "template": "blue",
            "title": {"tag": "plain_text", "content": f"ğŸ“Œ ä¸­ä¼˜å…ˆçº§Benchmarkå€™é€‰ ({len(candidates)}æ¡)"}
        },
        "elements": elements
    }

def _build_low_priority_card(self, candidates: List[ScoredCandidate]) -> dict:
    """ä½ä¼˜å…ˆçº§å¡ç‰‡ï¼šä¿æŒç®€æ´ï¼ˆä»…æ€»åˆ†ï¼‰"""
    # ä¿æŒç°æœ‰å®ç°ä¸å˜
    pass
```

**å±•ç¤ºæ•ˆæœé¢„æœŸ**ï¼š

**Highä¼˜å…ˆçº§å¡ç‰‡**ï¼š
```
ğŸ”¥ é«˜ä¼˜å…ˆçº§Benchmarkå€™é€‰ (3æ¡)

**AgentBench: Evaluating LLMs as Agents**
æ¥æº: arXiv | æ€»åˆ†: 8.2/10

èƒ½åŠ›åŸŸ: 8.5 (è§„åˆ’8.5 å·¥å…·9.0 æ¨ç†8.0)
é£é™©åŸŸ: 7.8 (å®‰å…¨8.0 é²æ£’7.5)
è¿è¥åŸŸ: 8.0

ğŸŸ¡ é£é™©ç­‰çº§: moderate

è¯„åˆ†ä¾æ®: ã€èƒ½åŠ›åŸŸåˆ†æã€‘è¯¥Benchmarkç³»ç»Ÿæ€§è¯„ä¼°äº†LLMçš„è§„åˆ’ã€å·¥å…·ä½¿ç”¨ã€æ¨ç†èƒ½åŠ›ï¼Œè¦†ç›–8ä¸ªåœºæ™¯...

[æŸ¥çœ‹è¯¦æƒ…] [é£ä¹¦å¤šç»´è¡¨]
```

**Mediumä¼˜å…ˆçº§å¡ç‰‡**ï¼š
```
ğŸ“Œ ä¸­ä¼˜å…ˆçº§Benchmarkå€™é€‰ (5æ¡)

**WebArena: Realistic Web Environment**
æ€»åˆ† 7.3/10 = èƒ½åŠ›7.0 + é£é™©6.8 + è¿è¥8.0 | é£é™©: moderate

[æŸ¥çœ‹è¯¦æƒ…]
```

---

## Task 7.2.3ï¼šè¡¥å……å•å…ƒæµ‹è¯•

### éœ€æ±‚è¯´æ˜

å½“å‰å…³é”®é€»è¾‘æ— æµ‹è¯•è¦†ç›–ï¼Œå­˜åœ¨å›é€€é£é™©ã€‚éœ€è¡¥å……ï¼š
1. `_normalize_scores` æµ‹è¯•ï¼ˆæ–°æ—§æ ¼å¼å…¼å®¹ï¼‰
2. `priority` å±æ€§æµ‹è¯•ï¼ˆé£é™©ç­‰çº§å½±å“ä¼˜å…ˆçº§ï¼‰
3. SQLiteåºåˆ—åŒ–å¾€è¿”æµ‹è¯•

### å®æ–½æ­¥éª¤

#### Test 1ï¼šLLMScorer._normalize_scoresæµ‹è¯•

```python
# æ–‡ä»¶ä½ç½®ï¼štests/test_scorer.pyï¼ˆæ–°å»ºæˆ–æ‰©å±•ï¼‰

import pytest
from src.scorer.llm_scorer import LLMScorer
from src.models import AgentCapabilityScores, RiskDomainScores, OperationalScores

class TestLLMScorer:

    def test_normalize_scores_v2_format(self):
        """æµ‹è¯•v2æ ¼å¼ï¼ˆä¸‰åŸŸå®Œæ•´ï¼‰æ­£å¸¸åŒ–"""
        scorer = LLMScorer()

        input_scores = {
            "capability_scores": {
                "planning_score": 8.5,
                "tool_use_score": 7.5,
                "memory_score": 6.0,
                "collaboration_score": 5.5,
                "reasoning_score": 7.0
            },
            "risk_scores": {
                "security_score": 7.5,
                "robustness_score": 6.5,
                "hallucination_risk": 6.0,
                "compliance_score": 8.0
            },
            "operational_scores": {
                "activity_score": 8.0,
                "reproducibility_score": 7.5,
                "license_score": 9.0,
                "novelty_score": 6.5,
                "relevance_score": 8.5
            },
            "reasoning": "æµ‹è¯•reasoning"
        }

        normalized = scorer._normalize_scores(input_scores)

        assert "capability_scores" in normalized
        assert "risk_scores" in normalized
        assert "operational_scores" in normalized
        assert normalized["capability_scores"]["planning_score"] == 8.5
        assert normalized["reasoning"] == "æµ‹è¯•reasoning"

    def test_normalize_scores_v1_compat(self):
        """æµ‹è¯•v1æ‰å¹³æ ¼å¼è‡ªåŠ¨è½¬æ¢"""
        scorer = LLMScorer()

        input_scores = {
            "activity_score": 7.5,
            "reproducibility_score": 8.0,
            "license_score": 7.0,
            "novelty_score": 6.5,
            "relevance_score": 8.5,
            "reasoning": "æ—§ç‰ˆè¯„åˆ†"
        }

        normalized = scorer._normalize_scores(input_scores)

        # åº”è‡ªåŠ¨è¡¥å…¨ä¸‰åŸŸç»“æ„
        assert "operational_scores" in normalized
        assert normalized["operational_scores"]["activity_score"] == 7.5
        assert "capability_scores" in normalized
        assert "risk_scores" in normalized

    def test_normalize_scores_clamp(self):
        """æµ‹è¯•åˆ†æ•°èŒƒå›´é™åˆ¶ï¼ˆ0-10ï¼‰"""
        scorer = LLMScorer()

        input_scores = {
            "capability_scores": {
                "planning_score": 15.0,  # è¶…å‡ºèŒƒå›´
                "tool_use_score": -2.0,  # ä½äº0
                "memory_score": 5.0,
                "collaboration_score": "invalid",  # éæ•°å­—
                "reasoning_score": 7.0
            },
            "risk_scores": {},
            "operational_scores": {},
            "reasoning": ""
        }

        normalized = scorer._normalize_scores(input_scores)

        assert normalized["capability_scores"]["planning_score"] == 10.0  # é™åˆ¶åˆ°10
        assert normalized["capability_scores"]["tool_use_score"] == 0.0   # é™åˆ¶åˆ°0
        assert normalized["capability_scores"]["collaboration_score"] == 0.0  # æ— æ•ˆå€¼å½’0
```

#### Test 2ï¼šScoredCandidate.priorityæµ‹è¯•

```python
# æ–‡ä»¶ä½ç½®ï¼štests/test_models.pyï¼ˆæ–°å»ºæˆ–æ‰©å±•ï¼‰

import pytest
from src.models import ScoredCandidate, AgentCapabilityScores, RiskDomainScores, OperationalScores

class TestScoredCandidate:

    def test_priority_v2_high_with_safe_risk(self):
        """æµ‹è¯•v2é«˜ä¼˜å…ˆçº§ï¼šé«˜åˆ†+ä½é£é™©"""
        cap = AgentCapabilityScores(
            planning_score=9.0, tool_use_score=8.5, memory_score=7.5,
            collaboration_score=7.0, reasoning_score=8.0
        )
        risk = RiskDomainScores(
            security_score=8.0, robustness_score=7.5,
            hallucination_risk=7.0, compliance_score=8.5
        )
        ops = OperationalScores(
            activity_score=8.0, reproducibility_score=8.5,
            license_score=9.0, novelty_score=7.0, relevance_score=8.5
        )

        candidate = ScoredCandidate(
            title="Test", url="https://test.com", source="arxiv",
            capability_scores=cap, risk_scores=risk, operational_scores=ops,
            risk_level="safe"
        )

        # total_scoreåº”è¯¥>8.0 ä¸” risk_level=safe â†’ high
        assert candidate.total_score >= 8.0
        assert candidate.priority == "high"

    def test_priority_v2_medium_with_high_risk(self):
        """æµ‹è¯•v2ä¸­ä¼˜å…ˆçº§ï¼šé«˜åˆ†ä½†é«˜é£é™©"""
        cap = AgentCapabilityScores(
            planning_score=9.0, tool_use_score=8.5, memory_score=7.5,
            collaboration_score=7.0, reasoning_score=8.0
        )
        risk = RiskDomainScores(
            security_score=4.0,  # ä½å®‰å…¨åˆ†
            robustness_score=4.5,
            hallucination_risk=5.0,
            compliance_score=5.5
        )
        ops = OperationalScores(
            activity_score=8.0, reproducibility_score=8.5,
            license_score=9.0, novelty_score=7.0, relevance_score=8.5
        )

        candidate = ScoredCandidate(
            title="Test", url="https://test.com", source="github",
            capability_scores=cap, risk_scores=risk, operational_scores=ops,
            risk_level="high"  # é«˜é£é™©
        )

        # è™½ç„¶æ€»åˆ†é«˜ï¼Œä½†é£é™©é«˜ â†’ ä¸èƒ½æ˜¯highä¼˜å…ˆçº§
        assert candidate.total_score >= 8.0
        assert candidate.priority != "high"
        assert candidate.priority in ["medium", "low"]

    def test_priority_v1_fallback(self):
        """æµ‹è¯•v1å…¼å®¹æ¨¡å¼ï¼ˆæ— ä¸‰åŸŸè¯„åˆ†ï¼‰"""
        candidate = ScoredCandidate(
            title="Old Test", url="https://test.com", source="arxiv",
            activity_score=8.5, reproducibility_score=8.0,
            license_score=7.5, novelty_score=7.0, relevance_score=8.0
        )

        # åº”ä½¿ç”¨æ—§ç‰ˆé€»è¾‘ï¼ˆä»…çœ‹total_scoreï¼‰
        assert candidate.total_score >= 8.0
        assert candidate.priority == "high"

    def test_total_score_v2_calculation(self):
        """æµ‹è¯•v2ä¸‰åŸŸåŠ æƒè®¡ç®—"""
        cap = AgentCapabilityScores(
            planning_score=8.0, tool_use_score=8.0, memory_score=8.0,
            collaboration_score=8.0, reasoning_score=8.0
        )  # capability_total = 8.0

        risk = RiskDomainScores(
            security_score=6.0, robustness_score=6.0,
            hallucination_risk=6.0, compliance_score=6.0
        )  # risk_total = 6.0

        ops = OperationalScores(
            activity_score=7.0, reproducibility_score=7.0,
            license_score=7.0, novelty_score=7.0, relevance_score=7.0
        )  # operational_total = 7.0

        candidate = ScoredCandidate(
            title="Test", url="https://test.com", source="github",
            capability_scores=cap, risk_scores=risk, operational_scores=ops
        )

        # total = 8.0*0.4 + 6.0*0.3 + 7.0*0.3 = 3.2 + 1.8 + 2.1 = 7.1
        assert abs(candidate.total_score - 7.1) < 0.01
```

#### Test 3ï¼šSQLiteåºåˆ—åŒ–å¾€è¿”æµ‹è¯•

```python
# æ–‡ä»¶ä½ç½®ï¼štests/test_sqlite_fallback.pyï¼ˆæ–°å»ºæˆ–æ‰©å±•ï¼‰

import pytest
from datetime import datetime
from src.storage.sqlite_fallback import SQLiteFallback
from src.models import ScoredCandidate, AgentCapabilityScores, RiskDomainScores, OperationalScores

class TestSQLiteFallback:

    def test_serialize_deserialize_v2_roundtrip(self):
        """æµ‹è¯•v2å€™é€‰åºåˆ—åŒ–å¾€è¿”"""
        original = ScoredCandidate(
            title="Test Benchmark",
            url="https://github.com/test/benchmark",
            source="github",
            abstract="Test abstract",
            capability_scores=AgentCapabilityScores(
                planning_score=8.5, tool_use_score=7.5,
                memory_score=6.5, collaboration_score=5.5,
                reasoning_score=7.0
            ),
            risk_scores=RiskDomainScores(
                security_score=7.5, robustness_score=6.5,
                hallucination_risk=6.0, compliance_score=8.0
            ),
            operational_scores=OperationalScores(
                activity_score=8.0, reproducibility_score=7.5,
                license_score=9.0, novelty_score=6.5,
                relevance_score=8.5
            ),
            reasoning="Test reasoning",
            risk_level="moderate",
            last_evaluated_at=datetime.now(),
            evaluation_version="v2.0"
        )

        # åºåˆ—åŒ–
        raw_dict = SQLiteFallback._serialize_raw(original)
        scores_dict = SQLiteFallback._serialize_scores(original)

        # ååºåˆ—åŒ–
        raw_restored = SQLiteFallback._deserialize_raw(raw_dict)
        scores_restored = SQLiteFallback._deserialize_scores(scores_dict)

        # é‡å»ºå¯¹è±¡
        restored = ScoredCandidate(**raw_restored, **scores_restored)

        # éªŒè¯å¾€è¿”ä¸€è‡´æ€§
        assert restored.title == original.title
        assert restored.url == original.url
        assert restored.capability_scores.planning_score == 8.5
        assert restored.risk_scores.security_score == 7.5
        assert restored.operational_scores.activity_score == 8.0
        assert restored.risk_level == "moderate"
        assert restored.evaluation_version == "v2.0"
        assert abs(restored.total_score - original.total_score) < 0.01

    def test_serialize_deserialize_v1_compat(self):
        """æµ‹è¯•v1å€™é€‰å…¼å®¹"""
        original = ScoredCandidate(
            title="Old Benchmark",
            url="https://arxiv.org/abs/1234.5678",
            source="arxiv",
            activity_score=7.5,
            reproducibility_score=8.0,
            license_score=7.0,
            novelty_score=6.5,
            relevance_score=8.5,
            reasoning="Old reasoning",
            evaluation_version="v1.0"
        )

        raw_dict = SQLiteFallback._serialize_raw(original)
        scores_dict = SQLiteFallback._serialize_scores(original)

        raw_restored = SQLiteFallback._deserialize_raw(raw_dict)
        scores_restored = SQLiteFallback._deserialize_scores(scores_dict)

        restored = ScoredCandidate(**raw_restored, **scores_restored)

        # v1å€™é€‰åº”è‡ªåŠ¨æ„å»ºoperational_scores
        assert restored.operational_scores is not None
        assert restored.operational_scores.activity_score == 7.5
        assert restored.evaluation_version == "v1.0"
```

**è¿è¡Œæµ‹è¯•**ï¼š
```bash
.venv/bin/python -m pytest tests/test_scorer.py -v
.venv/bin/python -m pytest tests/test_models.py -v
.venv/bin/python -m pytest tests/test_sqlite_fallback.py -v
```

---

## éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶

**1. é£ä¹¦å¤šç»´è¡¨å­—æ®µ**ï¼š
- [ ] 14ä¸ªæ–°å­—æ®µæˆåŠŸåˆ›å»ºï¼ˆæˆ–å·²å­˜åœ¨ï¼‰
- [ ] v2å€™é€‰å†™å…¥æ—¶æ‰€æœ‰å­—æ®µæœ‰å€¼ï¼ˆéç©ºï¼‰
- [ ] v1å€™é€‰å†™å…¥æ—¶ä»…operational_totalæœ‰å€¼ï¼Œä¸‰åŸŸå­—æ®µä¸º0æˆ–ç©º
- [ ] æ‰‹åŠ¨æ£€æŸ¥é£ä¹¦è¡¨æ ¼ï¼šæ‰“å¼€1æ¡v2è®°å½•ï¼ŒéªŒè¯capability_total/risk_levelç­‰å­—æ®µå¯è§

**2. é£ä¹¦é€šçŸ¥å¡ç‰‡**ï¼š
- [ ] Highä¼˜å…ˆçº§æ˜¾ç¤ºå®Œæ•´ä¸‰åŸŸè¯„åˆ† + é£é™©ç­‰çº§ + reasoningæ‘˜è¦
- [ ] Mediumä¼˜å…ˆçº§æ˜¾ç¤ºä¸‰åŸŸæ€»åˆ† + é£é™©ç­‰çº§
- [ ] Lowä¼˜å…ˆçº§ä¿æŒç®€æ´ï¼ˆä»…æ€»åˆ†ï¼‰
- [ ] æ‰‹åŠ¨æµ‹è¯•ï¼šè¿è¡Œ`scripts/test_layered_notification.py`ï¼Œæ£€æŸ¥é£ä¹¦æ”¶åˆ°çš„å¡ç‰‡æ ¼å¼

**3. å•å…ƒæµ‹è¯•**ï¼š
- [ ] `test_normalize_scores_v2_format` é€šè¿‡
- [ ] `test_normalize_scores_v1_compat` é€šè¿‡
- [ ] `test_normalize_scores_clamp` é€šè¿‡
- [ ] `test_priority_v2_high_with_safe_risk` é€šè¿‡
- [ ] `test_priority_v2_medium_with_high_risk` é€šè¿‡
- [ ] `test_serialize_deserialize_v2_roundtrip` é€šè¿‡
- [ ] æ‰€æœ‰æµ‹è¯•è¦†ç›–ç‡ â‰¥ 80%

### æ€§èƒ½éªŒæ”¶

- [ ] é£ä¹¦å†™å…¥æ—¶é—´å¢åŠ  < 10%ï¼ˆæ–°å¢å­—æ®µä¸åº”æ˜¾è‘—é™ä½æ€§èƒ½ï¼‰
- [ ] é£ä¹¦é€šçŸ¥æ¨é€æ—¶é—´ < 3ç§’ï¼ˆå¡ç‰‡å†…å®¹æ›´å¤æ‚ä¸åº”è¶…æ—¶ï¼‰

### å…¼å®¹æ€§éªŒæ”¶

- [ ] æ—§ç‰ˆå€™é€‰ï¼ˆv1.0ï¼‰åœ¨æ–°ç³»ç»Ÿä¸­æ­£å¸¸æ˜¾ç¤ºï¼ˆä¸æŠ¥é”™ï¼‰
- [ ] æ–°ç‰ˆå€™é€‰ï¼ˆv2.0ï¼‰åœ¨é£ä¹¦ä¸­æ­£ç¡®å±•ç¤ºä¸‰åŸŸè¯„åˆ†
- [ ] SQLiteé™çº§å¤‡ä»½æ­£å¸¸ï¼ˆv2å€™é€‰å†™å…¥åå¯æ¢å¤ï¼‰

---

## å¼ºåˆ¶çº¦æŸ

### ä»£ç è§„èŒƒ

1. **PEP8å¼ºåˆ¶éµå®ˆ**ï¼š
   ```bash
   black src/storage/feishu_storage.py src/notifier/feishu_notifier.py
   ruff check src/storage/ src/notifier/ --fix
   ```

2. **å…³é”®é€»è¾‘å¿…é¡»ä¸­æ–‡æ³¨é‡Š**ï¼š
   ```python
   # å…¼å®¹v1æ‰å¹³ç»“æ„ï¼šå°†æ—§ç‰ˆ5ç»´è¯„åˆ†è½¬æ¢ä¸ºoperational_scores
   if operational is None and all(key in scores for key in [...]):
       operational = {...}
   ```

3. **é­”æ³•æ•°å­—å¿…é¡»å¸¸é‡åŒ–**ï¼š
   ```python
   # Bad
   reasoning_preview = candidate.reasoning[:200]

   # Good
   REASONING_PREVIEW_LENGTH: Final[int] = 200
   reasoning_preview = candidate.reasoning[:constants.REASONING_PREVIEW_LENGTH]
   ```

### æµ‹è¯•è¦æ±‚

1. **å…³é”®è·¯å¾„å¿…é¡»æµ‹è¯•**ï¼š
   - `_normalize_scores` (3ä¸ªæµ‹è¯•)
   - `priority` å±æ€§ (4ä¸ªæµ‹è¯•)
   - SQLiteåºåˆ—åŒ– (2ä¸ªæµ‹è¯•)

2. **æµ‹è¯•å¿…é¡»ç‹¬ç«‹**ï¼š
   - ä¸ä¾èµ–å¤–éƒ¨APIï¼ˆmocké£ä¹¦APIè°ƒç”¨ï¼‰
   - ä¸ä¾èµ–ç¯å¢ƒå˜é‡ï¼ˆä½¿ç”¨fixtureæä¾›é…ç½®ï¼‰

3. **æµ‹è¯•å¿…é¡»å¯é‡å¤**ï¼š
   - å›ºå®šéšæœºç§å­
   - å›ºå®šæ—¶é—´æˆ³ï¼ˆç”¨freezegunï¼‰

### å‘åå…¼å®¹

1. **ç»å¯¹ç¦æ­¢ç ´åv1æ•°æ®**ï¼š
   - v1å€™é€‰å¿…é¡»èƒ½æ­£å¸¸è¯»å–ã€æ˜¾ç¤ºã€æ¨é€
   - é£ä¹¦æ—§è®°å½•ä¸å¾—å› æ–°å­—æ®µè€ŒæŠ¥é”™

2. **é™çº§ç­–ç•¥**ï¼š
   - æ–°å­—æ®µç¼ºå¤±æ—¶ä½¿ç”¨é»˜è®¤å€¼
   - Pydanticå¯¹è±¡ä¸ºNoneæ—¶å›é€€åˆ°æ‰å¹³å­—æ®µ

3. **ç‰ˆæœ¬æ ‡è¯†**ï¼š
   - æ‰€æœ‰æ–°è¯„åˆ†å¿…é¡»æ ‡è®°`evaluation_version="v2.0"`
   - é£ä¹¦å¡ç‰‡æ˜¾ç¤ºç‰ˆæœ¬å·ï¼ˆå¯é€‰ï¼‰

---

## å®æ–½æ—¶é—´çº¿

| é˜¶æ®µ | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ |
|------|------|---------|
| 7.2.1 | é£ä¹¦å­—æ®µæ˜ å°„ | 2å°æ—¶ |
| 7.2.2 | é€šçŸ¥å¡ç‰‡æ›´æ–° | 3å°æ—¶ |
| 7.2.3 | å•å…ƒæµ‹è¯•è¡¥å…… | 2å°æ—¶ |
| **æ€»è®¡** | | **7å°æ—¶** |

---

## äº¤ä»˜ç‰©æ¸…å•

### æ–°å¢æ–‡ä»¶

- [ ] `scripts/check_feishu_fields.py` - é£ä¹¦å­—æ®µæ£€æŸ¥è„šæœ¬
- [ ] `scripts/create_feishu_fields_v2.py` - é£ä¹¦å­—æ®µåˆ›å»ºè„šæœ¬
- [ ] `tests/test_scorer.py` - LLMScorerå•å…ƒæµ‹è¯•
- [ ] `tests/test_models.py` - ScoredCandidateå•å…ƒæµ‹è¯•
- [ ] `tests/test_sqlite_fallback.py` - SQLiteåºåˆ—åŒ–æµ‹è¯•

### ä¿®æ”¹æ–‡ä»¶

- [ ] `src/storage/feishu_storage.py` - æ–°å¢14å­—æ®µå†™å…¥é€»è¾‘
- [ ] `src/notifier/feishu_notifier.py` - ä¸‰åŸŸè¯„åˆ†å¡ç‰‡å±•ç¤º
- [ ] `src/common/constants.py` - æ–°å¢å¸¸é‡ï¼ˆå¦‚æœ‰ï¼‰

### æ–‡æ¡£æ›´æ–°

- [ ] `.claude/CLAUDE.md` - æ›´æ–°Phase 7è¿›åº¦ï¼ˆ7.1å®Œæˆ â†’ 7.2å®Œæˆï¼‰
- [ ] `docs/phase7-test-report.md` - æ‰‹åŠ¨æµ‹è¯•æŠ¥å‘Šï¼ˆé£ä¹¦æˆªå›¾ï¼‰

---

## åç»­è®¡åˆ’ï¼ˆPhase 7.3-7.5ï¼‰

å®Œæˆæœ¬é˜¶æ®µåï¼ŒPhase 7å‰©ä½™ä»»åŠ¡ï¼š

- **Phase 7.3** (Week 4): Task 3å®‰å…¨éªŒè¯å™¨ + Task 2è‡ªè¿›åŒ–æ ·æœ¬æ± 
- **Phase 7.4** (Week 5): Task 4æŒç»­å­¦ä¹ è°ƒåº¦ + Task 5åŒè½¨ä¿¡æ¯æŠ½å–
- **Phase 7.5** (Week 6): é›†æˆæµ‹è¯• + ä¸Šçº¿éƒ¨ç½²

---

## æ³¨æ„äº‹é¡¹

### Codexæ‰§è¡Œè¦æ±‚

1. **ä¸¥æ ¼æŒ‰ç…§æœ¬æ–‡æ¡£å®æ–½**ï¼Œä¸å¾—è‡ªè¡Œä¿®æ”¹è®¾è®¡
2. **æ–‡æ¡£ä¸æ¸…æ™°æ—¶å…ˆè¯¢é—®**ï¼Œä¸å¾—çŒœæµ‹
3. **å®Œæˆåé€šçŸ¥Claude CodeéªŒæ”¶**ï¼Œæä¾›ï¼š
   - æ”¹åŠ¨æ–‡ä»¶æ¸…å•
   - ç¼–è¯‘éªŒè¯ç»“æœ
   - æµ‹è¯•è¿è¡Œæˆªå›¾
   - é£ä¹¦æ¨é€æˆªå›¾ï¼ˆæ‰‹åŠ¨æµ‹è¯•ï¼‰

### Claude CodeéªŒæ”¶è¦æ±‚

1. **ä»£ç review**ï¼šæ£€æŸ¥PEP8ã€é­”æ³•æ•°å­—ã€ä¸­æ–‡æ³¨é‡Š
2. **åŠŸèƒ½æµ‹è¯•**ï¼šè¿è¡Œ`src/main.py`å®Œæ•´æµç¨‹
3. **é£ä¹¦éªŒè¯**ï¼šæ£€æŸ¥å¤šç»´è¡¨å­—æ®µå’Œé€šçŸ¥å¡ç‰‡
4. **æµ‹è¯•æ‰§è¡Œ**ï¼šè¿è¡Œpytestç¡®è®¤è¦†ç›–ç‡

---

**é¢„æœŸå®Œæˆæ—¶é—´**ï¼š2025-11-14 18:00å‰

**ä¼˜å…ˆçº§**ï¼šğŸ”´ Criticalï¼ˆé˜»å¡Phase 7åç»­ä»»åŠ¡ï¼‰
