# BenchScope Phase 2: åŠŸèƒ½å¢å¼ºå¼€å‘æŒ‡ä»¤

## å½“å‰çŠ¶æ€ âœ…

**Phase 1 (MVP) å·²å®Œæˆ**ï¼š
- âœ“ å¤šæºæ•°æ®é‡‡é›† (arXiv, GitHub Trending, Papers with Code)
- âœ“ LLMæ™ºèƒ½è¯„åˆ† (gpt-4o + Redisç¼“å­˜)
- âœ“ é£ä¹¦å¤šç»´è¡¨æ ¼å­˜å‚¨ + SQLiteé™çº§
- âœ“ é£ä¹¦Webhooké€šçŸ¥
- âœ“ GitHub Actionsè‡ªåŠ¨åŒ–
- âœ“ ä»“åº“å·²éƒ¨ç½²: https://github.com/JasonRobertDestiny/BenchScope

**ä»£ç è´¨é‡**ï¼š
- å•å…ƒæµ‹è¯•è¦†ç›–
- PEP8è§„èŒƒ
- å®Œæ•´æ–‡æ¡£
- æˆæœ¬ä¼˜åŒ– (Â¥1/æœˆ)

---

## Phase 2 ç›®æ ‡

åœ¨MVPåŸºç¡€ä¸Šå¢å¼ºä»¥ä¸‹èƒ½åŠ›ï¼š

### 1ï¸âƒ£ æ•°æ®æºæ‰©å±•
- **HuggingFace Hub**: ç›‘æ§æ–°å¢Benchmarkæ•°æ®é›†
- **Leaderboardè¿½è¸ª**: ç›‘æ§MMLUã€HumanEvalç­‰æ¦œå•å˜åŒ–
- **Twitterç›‘æ§**: å…³é”®è¯å®æ—¶è¿½è¸ª (å¯é€‰)

### 2ï¸âƒ£ æ€§èƒ½ä¼˜åŒ–
- **å¹¶å‘é‡‡é›†**: asyncio.gatherä¼˜åŒ–ï¼Œ10xæé€Ÿ
- **æ‰¹é‡å†™å…¥**: é£ä¹¦APIæ‰¹é‡ä¼˜åŒ– (20â†’100æ¡/æ‰¹)
- **å¢é‡æ›´æ–°**: é¿å…é‡å¤é‡‡é›†å·²å¤„ç†æ•°æ®

### 3ï¸âƒ£ æ™ºèƒ½å¢å¼º
- **ç›¸ä¼¼åº¦å»é‡**: ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦æ£€æµ‹é‡å¤Benchmark
- **è¶‹åŠ¿åˆ†æ**: è¯†åˆ«ç ”ç©¶çƒ­ç‚¹å’Œæ–°å…´æ–¹å‘
- **æ™ºèƒ½æ¨è**: åŸºäºå›¢é˜Ÿå†å²åå¥½æ¨è

### 4ï¸âƒ£ ç›‘æ§ä¸å‘Šè­¦
- **é”™è¯¯å‘Šè­¦**: é£ä¹¦æœºå™¨äººæ¨é€é‡‡é›†å¤±è´¥é€šçŸ¥
- **è´¨é‡ç›‘æ§**: ç»Ÿè®¡æ¯æ—¥é‡‡é›†æˆåŠŸç‡ã€è¯„åˆ†åˆ†å¸ƒ
- **æˆæœ¬è¿½è¸ª**: OpenAI APIä½¿ç”¨é‡ç›‘æ§

---

## å¼€å‘ä»»åŠ¡æ¸…å•

### Task 1: HuggingFaceæ•°æ®é›†ç›‘æ§ (ä¼˜å…ˆçº§: é«˜)

**ç›®æ ‡**: é‡‡é›†HuggingFaceä¸Šæ–°å¢çš„Benchmarkç›¸å…³æ•°æ®é›†

**å®ç°è¦ç‚¹**:
```python
# src/collectors/huggingface_collector.py
from huggingface_hub import HfApi, DatasetFilter

class HuggingFaceCollector:
    async def collect(self) -> list[RawCandidate]:
        """é‡‡é›†HuggingFace Benchmarkæ•°æ®é›†"""
        api = HfApi()
        datasets = api.list_datasets(
            filter=DatasetFilter(task_categories=["text-generation", "question-answering"]),
            search="benchmark OR evaluation",
            sort="lastModified",
            limit=50
        )

        candidates = []
        for ds in datasets:
            if self._is_benchmark_dataset(ds):
                candidates.append(self._to_candidate(ds))

        return candidates

    def _is_benchmark_dataset(self, dataset) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºBenchmarkæ•°æ®é›†"""
        # æ£€æŸ¥å…³é”®è¯: benchmark, evaluation, test set
        # æ£€æŸ¥READMEå†…å®¹
        # æ£€æŸ¥ä¸‹è½½é‡ >100
        pass
```

**ä¾èµ–**: `huggingface_hub>=0.20.0`

**é…ç½®**:
```yaml
# config/sources.yaml
huggingface:
  keywords: ["benchmark", "evaluation", "leaderboard"]
  task_categories: ["text-generation", "question-answering", "code"]
  min_downloads: 100
  update_interval: "daily"
```

**éªŒè¯**:
- [ ] èƒ½å¤Ÿé‡‡é›†åˆ°æœ€æ–°Benchmarkæ•°æ®é›†
- [ ] æ­£ç¡®æå–æ ‡é¢˜ã€æè¿°ã€ä¸‹è½½é‡
- [ ] è¿‡æ»¤æ‰éBenchmarkæ•°æ®é›†

---

### Task 2: æ’è¡Œæ¦œå˜åŒ–è¿½è¸ª (ä¼˜å…ˆçº§: é«˜)

**ç›®æ ‡**: ç›‘æ§Papers with Codeæ’è¡Œæ¦œSOTAå˜åŒ–

**å®ç°è¦ç‚¹**:
```python
# src/tracker/leaderboard_tracker.py
class LeaderboardTracker:
    async def track_changes(self, task: str) -> list[LeaderboardChange]:
        """è¿½è¸ªæ’è¡Œæ¦œå˜åŒ–"""
        current = await self._fetch_leaderboard(task)
        previous = await self._load_from_cache(task)

        changes = []
        for metric in current.metrics:
            if metric.value != previous.get(metric.name):
                changes.append(LeaderboardChange(
                    task=task,
                    metric=metric.name,
                    old_value=previous.get(metric.name),
                    new_value=metric.value,
                    model=metric.model_name,
                    timestamp=datetime.now()
                ))

        await self._save_to_cache(task, current)
        return changes
```

**è¿½è¸ªä»»åŠ¡**:
- MMLU (å¤šä»»åŠ¡è¯­è¨€ç†è§£)
- HumanEval (ä»£ç ç”Ÿæˆ)
- GSM8K (æ•°å­¦æ¨ç†)
- MATH (æ•°å­¦é—®é¢˜)
- SWE-bench (è½¯ä»¶å·¥ç¨‹)

**é€šçŸ¥æ ¼å¼**:
```
ğŸ† æ’è¡Œæ¦œæ›´æ–° - MMLU
ğŸ¥‡ æ–°çºªå½•: GPT-4.5 è¾¾åˆ° 92.3% (+2.1%)
ğŸ“ˆ è¶…è¶Š: GPT-4 (90.2%)
ğŸ“… æ›´æ–°æ—¶é—´: 2025-11-13
```

**éªŒè¯**:
- [ ] èƒ½å¤Ÿæ£€æµ‹åˆ°SOTAå˜åŒ–
- [ ] é€šçŸ¥åŒ…å«æ–°æ—§å¯¹æ¯”
- [ ] ç¼“å­˜é¿å…é‡å¤æ£€æŸ¥

---

### Task 3: å¹¶å‘é‡‡é›†ä¼˜åŒ– (ä¼˜å…ˆçº§: ä¸­)

**ç›®æ ‡**: é‡‡é›†é€Ÿåº¦ä»ä¸²è¡Œ20åˆ†é’Ÿ â†’ å¹¶å‘5åˆ†é’Ÿ

**å®ç°è¦ç‚¹**:
```python
# src/main.py
async def main():
    """å¹¶å‘é‡‡é›†æµç¨‹"""
    collectors = [
        ArxivCollector(),
        GitHubCollector(),
        PwCCollector(),
        HuggingFaceCollector(),  # æ–°å¢
    ]

    # å¹¶å‘é‡‡é›†
    results = await asyncio.gather(
        *[collector.collect() for collector in collectors],
        return_exceptions=True  # å®¹é”™
    )

    # åˆå¹¶ç»“æœ
    all_candidates = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            logger.error(f"é‡‡é›†å™¨ {collectors[i].__class__.__name__} å¤±è´¥: {result}")
        else:
            all_candidates.extend(result)

    # å¹¶å‘è¯„åˆ† (æ‰¹é‡10ä¸ª)
    scorer = LLMScorer()
    scored = []
    for batch in batched(all_candidates, 10):  # Python 3.12+
        scored.extend(await asyncio.gather(
            *[scorer.score(c) for c in batch]
        ))

    # æ‰¹é‡å­˜å‚¨ (100æ¡/æ‰¹)
    storage = StorageManager()
    await storage.batch_save(scored, batch_size=100)
```

**æ€§èƒ½ç›®æ ‡**:
- é‡‡é›†æ—¶é—´: <5åˆ†é’Ÿ
- LLMè¯„åˆ†å¹¶å‘åº¦: 10 (å—APIé™åˆ¶)
- é£ä¹¦æ‰¹é‡å†™å…¥: 100æ¡/æ‰¹

**éªŒè¯**:
- [ ] æ€»æ‰§è¡Œæ—¶é—´ <10åˆ†é’Ÿ
- [ ] APIé™æµæ­£ç¡®å¤„ç†
- [ ] å¹¶å‘é”™è¯¯ä¸å½±å“å…¶ä»–é‡‡é›†å™¨

---

### Task 4: å‘é‡å»é‡ (ä¼˜å…ˆçº§: ä¸­)

**ç›®æ ‡**: æ£€æµ‹é‡å¤æˆ–é«˜åº¦ç›¸ä¼¼çš„Benchmark

**å®ç°è¦ç‚¹**:
```python
# src/dedup/vector_dedup.py
from sentence_transformers import SentenceTransformer

class VectorDeduplicator:
    def __init__(self):
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.threshold = 0.85  # ç›¸ä¼¼åº¦é˜ˆå€¼

    async def deduplicate(self, candidates: list[RawCandidate]) -> list[RawCandidate]:
        """å‘é‡å»é‡"""
        if not candidates:
            return []

        # ç¼–ç æ‰€æœ‰å€™é€‰
        texts = [f"{c.title} {c.abstract}" for c in candidates]
        embeddings = self.model.encode(texts, show_progress_bar=False)

        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        from sklearn.metrics.pairwise import cosine_similarity
        sim_matrix = cosine_similarity(embeddings)

        # è´ªå¿ƒå»é‡
        keep = []
        used = set()
        for i, candidate in enumerate(candidates):
            if i in used:
                continue
            keep.append(candidate)
            # æ ‡è®°ç›¸ä¼¼é¡¹
            for j in range(i+1, len(candidates)):
                if sim_matrix[i][j] > self.threshold:
                    used.add(j)
                    logger.info(f"å»é‡: {candidates[j].title} (ä¸ {candidate.title} ç›¸ä¼¼åº¦ {sim_matrix[i][j]:.2f})")

        return keep
```

**ä¾èµ–**: `sentence-transformers>=2.2.0`, `scikit-learn>=1.3.0`

**éªŒè¯**:
- [ ] èƒ½å¤Ÿè¯†åˆ«é«˜åº¦ç›¸ä¼¼çš„Benchmark
- [ ] å»é‡ç‡åˆç† (10-20%)
- [ ] ä¸è¯¯åˆ çœŸæ­£ä¸åŒçš„Benchmark

---

### Task 5: é”™è¯¯å‘Šè­¦ç³»ç»Ÿ (ä¼˜å…ˆçº§: ä½)

**ç›®æ ‡**: é‡‡é›†å¤±è´¥æ—¶é£ä¹¦å‘Šè­¦

**å®ç°è¦ç‚¹**:
```python
# src/notifier/error_notifier.py
class ErrorNotifier:
    async def notify_failure(self, error: Exception, context: dict):
        """å‘é€é”™è¯¯å‘Šè­¦"""
        card = {
            "msg_type": "interactive",
            "card": {
                "header": {"title": {"tag": "plain_text", "content": "âš ï¸ BenchScope é‡‡é›†å¤±è´¥"}},
                "elements": [
                    {"tag": "div", "text": {"tag": "lark_md", "content": f"**é”™è¯¯ç±»å‹**: {type(error).__name__}"}},
                    {"tag": "div", "text": {"tag": "lark_md", "content": f"**é”™è¯¯ä¿¡æ¯**: {str(error)}"}},
                    {"tag": "div", "text": {"tag": "lark_md", "content": f"**é‡‡é›†å™¨**: {context['collector']}"}},
                    {"tag": "div", "text": {"tag": "lark_md", "content": f"**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"}},
                ]
            }
        }
        await self._send_card(card)
```

**è§¦å‘æ¡ä»¶**:
- é‡‡é›†å™¨è¿ç»­å¤±è´¥3æ¬¡
- LLMè¯„åˆ†æˆåŠŸç‡ <50%
- é£ä¹¦å†™å…¥å¤±è´¥

**éªŒè¯**:
- [ ] é”™è¯¯æ—¶æ”¶åˆ°å‘Šè­¦
- [ ] å‘Šè­¦ä¿¡æ¯å®Œæ•´
- [ ] é¿å…å‘Šè­¦é£æš´ (5åˆ†é’Ÿå†…æœ€å¤š1æ¡)

---

### Task 6: è¶‹åŠ¿åˆ†æ (ä¼˜å…ˆçº§: ä½)

**ç›®æ ‡**: è¯†åˆ«ç ”ç©¶çƒ­ç‚¹

**å®ç°è¦ç‚¹**:
```python
# src/analytics/trend_analyzer.py
class TrendAnalyzer:
    async def analyze_trends(self, days=30) -> list[Trend]:
        """åˆ†æè¶‹åŠ¿"""
        # ä»SQLiteè¯»å–30å¤©æ•°æ®
        candidates = await self._load_recent_candidates(days)

        # æå–å…³é”®è¯
        keywords = self._extract_keywords(candidates)

        # ç»Ÿè®¡é¢‘ç‡å˜åŒ–
        trends = []
        for keyword, frequency in keywords.items():
            baseline = self._get_baseline_frequency(keyword, days=60)
            if frequency / baseline > 1.5:  # å¢é•¿50%+
                trends.append(Trend(
                    keyword=keyword,
                    frequency=frequency,
                    growth_rate=(frequency - baseline) / baseline,
                    related_papers=[c.title for c in candidates if keyword in c.title.lower()]
                ))

        return sorted(trends, key=lambda t: t.growth_rate, reverse=True)
```

**å‘¨æŠ¥å†…å®¹**:
- æœ¬å‘¨çƒ­ç‚¹å…³é”®è¯ Top 10
- æ–°å…´Benchmarkç±»å‹
- ç ”ç©¶é¢†åŸŸåˆ†å¸ƒå˜åŒ–

**éªŒè¯**:
- [ ] èƒ½å¤Ÿè¯†åˆ«çƒ­ç‚¹å…³é”®è¯
- [ ] å¢é•¿ç‡è®¡ç®—å‡†ç¡®
- [ ] å‘¨æŠ¥è‡ªåŠ¨ç”Ÿæˆ

---

## æŠ€æœ¯è§„èŒƒ

### ä»£ç è´¨é‡
- **ç±»å‹æ³¨è§£**: æ‰€æœ‰å…¬å…±å‡½æ•°å¿…é¡»æœ‰ç±»å‹æ ‡æ³¨
- **æ–‡æ¡£å­—ç¬¦ä¸²**: å…³é”®é€»è¾‘ç”¨ä¸­æ–‡æ³¨é‡Š
- **é”™è¯¯å¤„ç†**: ä½¿ç”¨`try-except`å¹¶è®°å½•æ—¥å¿—
- **å•å…ƒæµ‹è¯•**: æ–°åŠŸèƒ½è¦†ç›–ç‡ >80%

### æ€§èƒ½è¦æ±‚
- **å¹¶å‘åº¦**: é‡‡é›†å™¨å¹¶å‘ï¼Œè¯„åˆ†10å¹¶å‘
- **è¶…æ—¶æ§åˆ¶**: å•æ¬¡APIè°ƒç”¨ <30ç§’
- **ç¼“å­˜ç­–ç•¥**: Redis 7å¤© + SQLiteæŒä¹…åŒ–

### å…¼å®¹æ€§
- **å‘åå…¼å®¹**: ä¸ç ´åPhase 1åŠŸèƒ½
- **é…ç½®éš”ç¦»**: æ–°åŠŸèƒ½é€šè¿‡`config/`æ§åˆ¶å¼€å…³
- **é™çº§ç­–ç•¥**: æ–°æ•°æ®æºå¤±è´¥ä¸å½±å“åŸæœ‰é‡‡é›†

---

## éªŒè¯æ¸…å•

Phase 2å¼€å‘å®Œæˆåï¼Œå¿…é¡»é€šè¿‡ä»¥ä¸‹éªŒè¯ï¼š

### åŠŸèƒ½éªŒè¯
- [ ] HuggingFaceé‡‡é›†æˆåŠŸ (â‰¥5ä¸ªæ•°æ®é›†)
- [ ] æ’è¡Œæ¦œå˜åŒ–æ£€æµ‹æ­£ç¡®
- [ ] å¹¶å‘é‡‡é›†æ—¶é—´ <10åˆ†é’Ÿ
- [ ] å‘é‡å»é‡ç‡ 10-20%
- [ ] é”™è¯¯å‘Šè­¦è§¦å‘æ­£å¸¸

### æ€§èƒ½éªŒè¯
- [ ] æ€»æ‰§è¡Œæ—¶é—´ <10åˆ†é’Ÿ
- [ ] LLMæˆæœ¬ <Â¥10/å¤©
- [ ] å†…å­˜å ç”¨ <500MB
- [ ] å¹¶å‘æ— æ­»é”

### è´¨é‡éªŒè¯
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] PEP8æ£€æŸ¥é€šè¿‡ (`ruff check .`)
- [ ] ç±»å‹æ£€æŸ¥é€šè¿‡ (`mypy src/`)
- [ ] æ— å®‰å…¨æ¼æ´

---

## éƒ¨ç½²æµç¨‹

### 1. æœ¬åœ°å¼€å‘æµ‹è¯•
```bash
# å®‰è£…æ–°ä¾èµ–
pip install -r requirements.txt

# è¿è¡Œå•å…ƒæµ‹è¯•
pytest tests/ -v

# æœ¬åœ°æµ‹è¯•è¿è¡Œ
python -m src.main
```

### 2. æ›´æ–°æ–‡æ¡£
- æ›´æ–° `README.md` æ–°åŠŸèƒ½è¯´æ˜
- æ›´æ–° `CLAUDE.md` æŠ€æœ¯æ ˆ
- åˆ›å»º `docs/phase2-features.md`

### 3. æäº¤ä»£ç 
```bash
git add .
git commit -m "feat(phase2): add HuggingFace collector and leaderboard tracking

- Add HuggingFace dataset monitoring
- Implement leaderboard change tracking for MMLU/HumanEval/etc
- Optimize with concurrent collection (5x speedup)
- Add vector-based deduplication
- Implement error notification system
- Add trend analysis for weekly reports"

git push origin main
```

### 4. GitHub Actionsæµ‹è¯•
- æ‰‹åŠ¨è§¦å‘workflowéªŒè¯
- æ£€æŸ¥æ—¥å¿—ç¡®è®¤æ–°åŠŸèƒ½è¿è¡Œæ­£å¸¸
- éªŒè¯é£ä¹¦é€šçŸ¥åŒ…å«æ–°æ•°æ®æº

---

## æˆåŠŸæ ‡å‡†

| æŒ‡æ ‡ | Phase 1 | Phase 2 ç›®æ ‡ |
|------|---------|-------------|
| æ•°æ®æºæ•°é‡ | 3 | 5+ |
| æ—¥é‡‡é›†é‡ | 20-50 | 50-100 |
| æ‰§è¡Œæ—¶é—´ | 20åˆ†é’Ÿ | <10åˆ†é’Ÿ |
| å»é‡å‡†ç¡®ç‡ | N/A | >90% |
| æˆæœ¬ | Â¥1/å¤© | <Â¥5/å¤© |
| è‡ªåŠ¨åŒ–ç¨‹åº¦ | æ•°æ®é‡‡é›† | æ•°æ®+åˆ†æ+å‘Šè­¦ |

---

## é£é™©æç¤º

1. **APIé™æµ**: HuggingFace/Twitterå¯èƒ½æœ‰é™æµï¼Œéœ€è¦å®ç°é€€é¿ç­–ç•¥
2. **æˆæœ¬å¢åŠ **: æ–°æ•°æ®æºå¢åŠ LLMè¯„åˆ†æ¬¡æ•°ï¼Œéœ€ç›‘æ§æˆæœ¬
3. **å¤æ‚åº¦ä¸Šå‡**: å¹¶å‘è°ƒè¯•éš¾åº¦å¢åŠ ï¼Œéœ€è¦å®Œå–„æ—¥å¿—
4. **å‘é‡è®¡ç®—**: sentence-transformersæ¨¡å‹è¾ƒå¤§ (90MB)ï¼Œé¦–æ¬¡ä¸‹è½½æ…¢

---

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨

**ç«‹å³å¼€å§‹ (å¿…é¡»)**:
1. æ·»åŠ HuggingFaceé‡‡é›†å™¨
2. å®ç°å¹¶å‘é‡‡é›†ä¼˜åŒ–

**è¿‘æœŸå®Œæˆ (æ¨è)**:
3. æ’è¡Œæ¦œè¿½è¸ª
4. å‘é‡å»é‡

**å¯é€‰å¢å¼º**:
5. é”™è¯¯å‘Šè­¦
6. è¶‹åŠ¿åˆ†æ

**Codexæ‰§è¡Œå‘½ä»¤**:
```bash
# æŒ‰é¡ºåºå®ç°Task 1-6
# æ¯ä¸ªTaskå®Œæˆåè¿è¡Œæµ‹è¯•
# æœ€åæ›´æ–°æ–‡æ¡£å¹¶æäº¤
```

---

**å½“å‰ä»“åº“**: https://github.com/JasonRobertDestiny/BenchScope
**Phase 1å®Œæˆåº¦**: 100% âœ…
**Phase 2ç›®æ ‡**: 6å‘¨å†…å®Œæˆæ ¸å¿ƒåŠŸèƒ½ ğŸš€
