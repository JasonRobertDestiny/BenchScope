# Phase 7: è¯„æµ‹ä½“ç³»å¢å¼º - Codexå¼€å‘æŒ‡ä»¤

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025-11-14
**ç›®æ ‡**: åŸºäºæœ€æ–°Agentè¯„æµ‹ç ”ç©¶ï¼Œé‡æ„BenchScopeè¯„åˆ†ä½“ç³»ï¼Œå¼•å…¥å¤šç»´åº¦èƒ½åŠ›è¯„ä¼°ã€å®‰å…¨é£é™©æ£€æµ‹å’ŒæŒç»­æ¼”è¿›æœºåˆ¶

---

## ä¸€ã€èƒŒæ™¯ä¸é—®é¢˜è¯Šæ–­

### å½“å‰ç³»ç»Ÿç—›ç‚¹ï¼ˆåŸºäºarXiv 2503.16416ç­‰æœ€æ–°ç ”ç©¶ï¼‰

**1. è¯„ä»·ç»´åº¦å•ä¸€**
- ç°çŠ¶: ä»…è¯„ä¼°æ´»è·ƒåº¦ã€å¯å¤ç°æ€§ã€è®¸å¯ã€æ–°é¢–æ€§ã€MGXé€‚é…åº¦ç­‰é™æ€ç‰¹å¾
- é—®é¢˜: ç¼ºä¹å¯¹Agentæ ¸å¿ƒèƒ½åŠ›ï¼ˆè§„åˆ’Planningã€å·¥å…·ä½¿ç”¨Tool Useã€è®°å¿†Memoryã€åä½œCollaborationï¼‰çš„åˆ¤å®š
- å½±å“: æ— æ³•åŒºåˆ†GUI/Web/Coding/DeepResearchåœºæ™¯çš„çœŸå®å·®å¼‚ï¼Œæ¨é€çš„Benchmarkå¯èƒ½ä¸é€‚åˆå®é™…åº”ç”¨

**2. é£é™©æ„ŸçŸ¥ç¼ºå¤±**
- ç°çŠ¶: æ— å®‰å…¨ã€é²æ£’ã€åˆè§„ç›¸å…³æŒ‡æ ‡
- é—®é¢˜: é‡‘èä¸é«˜ä»·å€¼é¢†åŸŸç ”ç©¶è¡¨æ˜ï¼Œä¼ ç»Ÿæ€§èƒ½åˆ†æ•°æ— æ³•æš´éœ²å¹»è§‰ã€è¶Šæƒè°ƒç”¨ã€æ—¶é—´é”™é…ç­‰ç³»ç»Ÿæ€§é£é™©
- å½±å“: æ¨é€åˆ°å€™é€‰æ± çš„Benchmarkå¯èƒ½åœ¨å®æˆ˜ä¸­ä¸å¯ç”¨æˆ–å­˜åœ¨å®‰å…¨éšæ‚£
- å‚è€ƒ: arXiv 2502.15865 - é‡‘èAgenté£é™©è¯„ä¼°ç ”ç©¶

**3. å®‰å…¨æ”»é˜²ç›²ç‚¹**
- ç°çŠ¶: æ— æ”»å‡»é¢åˆ†ææˆ–å®‰å…¨æš´éœ²è¯„åˆ†
- é—®é¢˜: RAS-Evalå®éªŒæ˜¾ç¤ºï¼Œé«˜çº§æ”»å‡»å¯å°†LLM Agentä»»åŠ¡å®Œæˆç‡é™ä½36.78%
- å½±å“: æ— æ³•ä¿è¯æ¨èçš„Benchmarkåœ¨å¯¹æŠ—ç¯å¢ƒä¸‹çš„é²æ£’æ€§
- å‚è€ƒ: arXiv 2506.15253 - RAS-Evalå®‰å…¨è¯„æµ‹

**4. ä¿¡æ¯æŠ½å–å‡†ç¡®æ€§é—®é¢˜**
- ç°çŠ¶: å®Œå…¨ä¾èµ–LLMå•æ¬¡æŠ½å–ï¼Œæ— æ ¡éªŒæœºåˆ¶
- é—®é¢˜: GPT-4åœ¨ç§‘å­¦ä¿¡æ¯æŠ½å–ä¸­å­˜åœ¨å¹»è§‰é—®é¢˜ï¼Œå°¤å…¶æ˜¯å›¾è¡¨ã€å•ä½ã€æ•°å€¼
- å½±å“: è®ºæ–‡é“¾æ¥ã€å¼€æºæ—¶é—´ã€è¯„ä¼°æŒ‡æ ‡ç­‰å…³é”®å­—æ®µå¯èƒ½ä¸å‡†ç¡®
- å‚è€ƒ: scisimple.com - GPT-4ç§‘å­¦ä¿¡æ¯æŠ½å–è¯„ä¼°

**5. é™æ€è¯„åˆ†ï¼Œæ— æ¼”è¿›æœºåˆ¶**
- ç°çŠ¶: å€™é€‰å…¥åº“åè¯„åˆ†å›ºå®šï¼Œä¸éšæ—¶é—´æ›´æ–°
- é—®é¢˜: Benchmarkè´¨é‡ä¼šéšç‰ˆæœ¬æ¼”è¿›ã€ç¤¾åŒºæ´»è·ƒåº¦å˜åŒ–è€Œå˜åŒ–
- å½±å“: æ— æ³•å‘ç°å·²è¿‡æ—¶æˆ–è´¨é‡ä¸‹é™çš„Benchmark
- å‚è€ƒ: arXiv 2505.11942 - LifelongAgentBenchæŒç»­è¯„æµ‹

---

## äºŒã€æ”¹è¿›æ–¹æ¡ˆæ¦‚è¿°

### æ ¸å¿ƒç›®æ ‡

**ä»å•ä¸€é™æ€è¯„åˆ† â†’ å¤šç»´åŠ¨æ€è¯„ä¼°**

```
æ—§æ¨¡å¼: 5ç»´é™æ€è¯„åˆ†(0-10) â†’ åŠ æƒæ€»åˆ† â†’ ä¸€æ¬¡æ€§å…¥åº“
æ–°æ¨¡å¼: 3åŸŸåŠ¨æ€è¯„ä¼°(èƒ½åŠ›+é£é™©+è¿è¥) â†’ å¤šè½®éªŒè¯ â†’ æŒç»­æ›´æ–°
```

### æ”¹è¿›ç­–ç•¥ï¼ˆ5å¤§æ–¹å‘ï¼‰

1. **é‡æ„è¯„åˆ†è¡¨** - èƒ½åŠ›åŸŸ + é£é™©åŸŸ + è¿è¥åŸŸä¸‰å¤§å—
2. **è‡ªè¿›åŒ–æ ·æœ¬æ± ** - é«˜ç½®ä¿¡é‡è¿° + æ‰°åŠ¨ç”Ÿæˆæ–°è¯„æµ‹æƒ…å¢ƒ
3. **å®‰å…¨/å¯æ§å›è·¯** - æ”»é˜²æµ‹è¯• + LLMè‡ªæˆ‘è¯„ä¼°
4. **æŒç»­å­¦ä¹ æ ¡éªŒ** - è·¨å‘¨æœŸå¤æµ‹ + åˆ†æ•°æ¼‚ç§»ç›‘æ§
5. **ä¿¡æ¯æŠ½å–åŒè½¨åˆ¶** - LLM + ä¼ ç»Ÿè§£æå™¨å¹¶è¡Œï¼Œä¸€è‡´æ€§æ£€æŸ¥

---

## ä¸‰ã€è¯¦ç»†å®ç°æ–¹æ¡ˆ

### Task 1: é‡æ„è¯„åˆ†æ¨¡å‹ (èƒ½åŠ›åŸŸ + é£é™©åŸŸ + è¿è¥åŸŸ)

#### 1.1 æ–°å¢æ•°æ®æ¨¡å‹å­—æ®µ

**æ–‡ä»¶**: `src/models.py`

åœ¨ `ScoredCandidate` æ¨¡å‹ä¸­æ–°å¢ï¼š

```python
from pydantic import BaseModel, Field
from typing import Optional, Dict

class AgentCapabilityScores(BaseModel):
    """Agentèƒ½åŠ›åŸŸè¯„åˆ†"""
    planning_score: float = Field(ge=0, le=10, description="è§„åˆ’èƒ½åŠ›ï¼šä»»åŠ¡åˆ†è§£ã€ç­–ç•¥åˆ¶å®š")
    tool_use_score: float = Field(ge=0, le=10, description="å·¥å…·ä½¿ç”¨ï¼šAPIè°ƒç”¨ã€è„šæœ¬æ‰§è¡Œ")
    memory_score: float = Field(ge=0, le=10, description="è®°å¿†èƒ½åŠ›ï¼šä¸Šä¸‹æ–‡ä¿æŒã€ä¿¡æ¯æ£€ç´¢")
    collaboration_score: float = Field(ge=0, le=10, description="åä½œèƒ½åŠ›ï¼šå¤šAgentäº¤äº’ã€ä»»åŠ¡ååŒ")
    reasoning_score: float = Field(ge=0, le=10, description="æ¨ç†èƒ½åŠ›ï¼šé€»è¾‘æ¨ç†ã€é—®é¢˜æ±‚è§£")

class RiskDomainScores(BaseModel):
    """é£é™©åŸŸè¯„åˆ†"""
    security_score: float = Field(ge=0, le=10, description="å®‰å…¨æ€§ï¼šæ— æ¶æ„ä»£ç ã€æƒé™æ§åˆ¶")
    robustness_score: float = Field(ge=0, le=10, description="é²æ£’æ€§ï¼šæŠ—æ”»å‡»ã€é”™è¯¯æ¢å¤")
    hallucination_risk: float = Field(ge=0, le=10, description="å¹»è§‰é£é™©ï¼š0=é«˜é£é™©, 10=æ— é£é™©")
    compliance_score: float = Field(ge=0, le=10, description="åˆè§„æ€§ï¼šéšç§ä¿æŠ¤ã€ä¼¦ç†è§„èŒƒ")

class OperationalScores(BaseModel):
    """è¿è¥åŸŸè¯„åˆ†ï¼ˆç°æœ‰æŒ‡æ ‡ï¼‰"""
    activity_score: float = Field(ge=0, le=10)
    reproducibility_score: float = Field(ge=0, le=10)
    license_score: float = Field(ge=0, le=10)
    novelty_score: float = Field(ge=0, le=10)
    relevance_score: float = Field(ge=0, le=10)

class ScoredCandidate(RawCandidate):
    """è¯„åˆ†åçš„å€™é€‰é¡¹ - é‡æ„ç‰ˆ"""
    # ä¸‰åŸŸè¯„åˆ†
    capability_scores: Optional[AgentCapabilityScores] = None
    risk_scores: Optional[RiskDomainScores] = None
    operational_scores: OperationalScores

    # ç»¼åˆæŒ‡æ ‡
    total_score: float  # ä¸‰åŸŸåŠ æƒæ€»åˆ†
    capability_total: float = 0.0  # èƒ½åŠ›åŸŸæ€»åˆ†
    risk_total: float = 0.0  # é£é™©åŸŸæ€»åˆ†
    operational_total: float = 0.0  # è¿è¥åŸŸæ€»åˆ†

    # ä¼˜å…ˆçº§ä¸çŠ¶æ€
    priority: str = "medium"  # high/medium/low
    risk_level: str = "unknown"  # safe/moderate/high/critical

    # å…ƒæ•°æ®
    reasoning: str = ""  # LLMè¯„åˆ†ä¾æ®
    last_evaluated_at: Optional[datetime] = None  # æœ€åè¯„åˆ†æ—¶é—´
    evaluation_version: str = "v2.0"  # è¯„åˆ†æ¨¡å‹ç‰ˆæœ¬
```

#### 1.2 æ›´æ–°å¸¸é‡é…ç½®

**æ–‡ä»¶**: `src/common/constants.py`

```python
# è¯„åˆ†æƒé‡ - ä¸‰åŸŸæ¨¡å‹
SCORE_WEIGHTS_V2: Final[dict[str, float]] = {
    "capability_domain": 0.40,  # èƒ½åŠ›åŸŸæƒé‡40%
    "risk_domain": 0.30,        # é£é™©åŸŸæƒé‡30%
    "operational_domain": 0.30, # è¿è¥åŸŸæƒé‡30%
}

# èƒ½åŠ›åŸŸå­æƒé‡
CAPABILITY_WEIGHTS: Final[dict[str, float]] = {
    "planning": 0.25,
    "tool_use": 0.25,
    "memory": 0.20,
    "collaboration": 0.15,
    "reasoning": 0.15,
}

# é£é™©åŸŸå­æƒé‡
RISK_WEIGHTS: Final[dict[str, float]] = {
    "security": 0.35,
    "robustness": 0.25,
    "hallucination_risk": 0.25,
    "compliance": 0.15,
}

# é£é™©ç­‰çº§é˜ˆå€¼
RISK_CRITICAL_THRESHOLD: Final[float] = 3.0  # é£é™©æ€»åˆ†<3.0ä¸ºä¸¥é‡
RISK_HIGH_THRESHOLD: Final[float] = 5.0
RISK_MODERATE_THRESHOLD: Final[float] = 7.0

# ä¼˜å…ˆçº§åˆ¤å®šé˜ˆå€¼ï¼ˆåŸºäºä¸‰åŸŸç»¼åˆï¼‰
PRIORITY_HIGH_THRESHOLD_V2: Final[float] = 8.0  # èƒ½åŠ›+é£é™©åŒé«˜
PRIORITY_MEDIUM_THRESHOLD_V2: Final[float] = 6.5
```

#### 1.3 å¢å¼ºLLMè¯„åˆ†Prompt

**æ–‡ä»¶**: `src/scorer/llm_scorer.py`

åœ¨ `_build_prompt` æ–¹æ³•ä¸­ï¼Œæ›¿æ¢ä¸ºä¸‰åŸŸè¯„åˆ†promptï¼š

```python
def _build_prompt(self, candidate: RawCandidate) -> str:
    """æ„å»ºä¸‰åŸŸè¯„åˆ†prompt"""

    # æ„å»ºä¸Šä¸‹æ–‡ï¼ˆä¿ç•™ç°æœ‰é€»è¾‘ï¼‰
    github_info = ""
    if candidate.github_url:
        github_info = f"\nGitHubé“¾æ¥: {candidate.github_url}"
        if candidate.github_stars is not None:
            github_info += f"\nGitHub Stars: {candidate.github_stars:,}"

    task_info = f"\nä»»åŠ¡ç±»å‹: {candidate.task_type}" if candidate.task_type else ""
    license_info = f"\nLicense: {candidate.license_type}" if candidate.license_type else ""

    return f"""è¯·å¯¹ä»¥ä¸‹AI Benchmarkå€™é€‰è¿›è¡Œ**ä¸‰åŸŸè¯„åˆ†**ï¼ˆ0-10åˆ†ï¼Œä¿ç•™ä¸€ä½å°æ•°ï¼‰ã€‚

å€™é€‰ä¿¡æ¯:
- æ ‡é¢˜: {candidate.title}
- æ¥æº: {candidate.source}
- URL: {candidate.url}
- æ‘˜è¦: {(candidate.abstract or 'N/A')[:800]}
{github_info}{task_info}{license_info}

---

## ä¸€ã€èƒ½åŠ›åŸŸè¯„åˆ† (Capability Domain)

è¯„ä¼°è¯¥Benchmarkå¯¹Agentæ ¸å¿ƒèƒ½åŠ›çš„è¦†ç›–ç¨‹åº¦ï¼š

1. **è§„åˆ’èƒ½åŠ› (planning_score)**
   - æ˜¯å¦è¯„æµ‹ä»»åŠ¡åˆ†è§£ã€ç­–ç•¥åˆ¶å®šã€ç›®æ ‡è®¾å®šèƒ½åŠ›ï¼Ÿ
   - ç¤ºä¾‹ï¼šWebArenaè¯„æµ‹Webä»»åŠ¡è§„åˆ’ â†’ 9åˆ†ï¼›MMLUæ— è§„åˆ’è¯„æµ‹ â†’ 2åˆ†

2. **å·¥å…·ä½¿ç”¨ (tool_use_score)**
   - æ˜¯å¦æ¶‰åŠAPIè°ƒç”¨ã€ä»£ç æ‰§è¡Œã€å¤–éƒ¨å·¥å…·é›†æˆï¼Ÿ
   - ç¤ºä¾‹ï¼šToolBenchè¯„æµ‹APIä½¿ç”¨ â†’ 10åˆ†ï¼›çº¯æ–‡æœ¬QA â†’ 1åˆ†

3. **è®°å¿†èƒ½åŠ› (memory_score)**
   - æ˜¯å¦è€ƒå¯Ÿé•¿æœŸè®°å¿†ã€ä¸Šä¸‹æ–‡ä¿æŒã€ä¿¡æ¯æ£€ç´¢ï¼Ÿ
   - ç¤ºä¾‹ï¼šLifelongBenchè¯„æµ‹è·¨ä¼šè¯è®°å¿† â†’ 9åˆ†ï¼›å•è½®å¯¹è¯ â†’ 3åˆ†

4. **åä½œèƒ½åŠ› (collaboration_score)**
   - æ˜¯å¦è¯„ä¼°å¤šAgentäº¤äº’ã€ä»»åŠ¡ååŒã€è§’è‰²åˆ†å·¥ï¼Ÿ
   - ç¤ºä¾‹ï¼šAgentVerseè¯„æµ‹å¤šAgentåä½œ â†’ 10åˆ†ï¼›å•Agentä»»åŠ¡ â†’ 0åˆ†

5. **æ¨ç†èƒ½åŠ› (reasoning_score)**
   - æ˜¯å¦æµ‹è¯•é€»è¾‘æ¨ç†ã€é—®é¢˜æ±‚è§£ã€çŸ¥è¯†è¿ç”¨ï¼Ÿ
   - ç¤ºä¾‹ï¼šMATHè¯„æµ‹æ•°å­¦æ¨ç† â†’ 9åˆ†ï¼›ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ â†’ 4åˆ†

---

## äºŒã€é£é™©åŸŸè¯„åˆ† (Risk Domain)

è¯„ä¼°è¯¥Benchmarkçš„å®‰å…¨æ€§ã€é²æ£’æ€§å’Œåˆè§„æ€§ï¼š

1. **å®‰å…¨æ€§ (security_score)**
   - æ•°æ®é›†/ä»£ç æ˜¯å¦åŒ…å«æ¶æ„å†…å®¹ã€éšç§æ³„éœ²ï¼Ÿ
   - æ˜¯å¦æœ‰å®‰å…¨é˜²æŠ¤æªæ–½ï¼ˆè¾“å…¥éªŒè¯ã€æƒé™æ§åˆ¶ï¼‰ï¼Ÿ
   - ç¤ºä¾‹ï¼šå®˜æ–¹å­¦æœ¯æ•°æ®é›† â†’ 9åˆ†ï¼›æœªéªŒè¯çš„çˆ¬è™«æ•°æ® â†’ 4åˆ†

2. **é²æ£’æ€§ (robustness_score)**
   - æ˜¯å¦æµ‹è¯•å¯¹æŠ—æ ·æœ¬ã€å¼‚å¸¸è¾“å…¥çš„å¤„ç†ï¼Ÿ
   - æ˜¯å¦æœ‰é”™è¯¯æ¢å¤æœºåˆ¶ï¼Ÿ
   - ç¤ºä¾‹ï¼šRAS-EvalåŒ…å«æ”»å‡»æµ‹è¯• â†’ 10åˆ†ï¼›æ— é²æ£’æ€§æµ‹è¯• â†’ 3åˆ†

3. **å¹»è§‰é£é™© (hallucination_risk)**
   - è¯„ä¼°æŒ‡æ ‡æ˜¯å¦å®¹æ˜“è¢«"è™šå‡é«˜åˆ†"è¯¯å¯¼ï¼Ÿ
   - æ•°æ®é›†æ˜¯å¦æœ‰éªŒè¯æœºåˆ¶ï¼Ÿ
   - ç¤ºä¾‹ï¼šå¯éªŒè¯ç­”æ¡ˆçš„æ•°æ®é›† â†’ 9åˆ†ï¼›ä¸»è§‚è¯„ä»· â†’ 4åˆ†

4. **åˆè§„æ€§ (compliance_score)**
   - æ˜¯å¦ç¬¦åˆéšç§ä¿æŠ¤ï¼ˆGDPR/HIPAAï¼‰ã€ä¼¦ç†è§„èŒƒï¼Ÿ
   - Licenseæ˜¯å¦å…è®¸å•†ä¸šä½¿ç”¨ï¼Ÿ
   - ç¤ºä¾‹ï¼šMIT License + å…¬å¼€æ•°æ® â†’ 10åˆ†ï¼›æœªçŸ¥License â†’ 5åˆ†

---

## ä¸‰ã€è¿è¥åŸŸè¯„åˆ† (Operational Domain)

è¯„ä¼°è¯¥Benchmarkçš„å¯ç»´æŠ¤æ€§å’Œå®ç”¨æ€§ï¼ˆä¿ç•™ç°æœ‰5ç»´ï¼‰ï¼š

1. **æ´»è·ƒåº¦ (activity_score)**: GitHub starsã€æœ€è¿‘æ›´æ–°é¢‘ç‡
2. **å¯å¤ç°æ€§ (reproducibility_score)**: ä»£ç ã€æ•°æ®ã€æ–‡æ¡£å®Œæ•´æ€§
3. **è®¸å¯åˆè§„ (license_score)**: MIT/Apacheä¼˜å…ˆ
4. **ä»»åŠ¡æ–°é¢–æ€§ (novelty_score)**: ä¸å·²æœ‰Benchmarkå·®å¼‚
5. **MGXé€‚é…åº¦ (relevance_score)**: ä¸å¤šæ™ºèƒ½ä½“/ä»£ç ç”Ÿæˆç›¸å…³æ€§

---

## è¾“å‡ºæ ¼å¼

è¯·è¾“å‡ºJSONï¼ŒåŒ…å«ä¸‰åŸŸè¯¦ç»†è¯„åˆ† + ç»¼åˆåˆ†æï¼š

```json
{{
  "capability_scores": {{
    "planning_score": 7.5,
    "tool_use_score": 9.0,
    "memory_score": 6.0,
    "collaboration_score": 8.5,
    "reasoning_score": 7.0
  }},
  "risk_scores": {{
    "security_score": 9.0,
    "robustness_score": 7.0,
    "hallucination_risk": 8.5,
    "compliance_score": 10.0
  }},
  "operational_scores": {{
    "activity_score": 8.5,
    "reproducibility_score": 9.0,
    "license_score": 10.0,
    "novelty_score": 7.0,
    "relevance_score": 8.0
  }},
  "reasoning": "ã€èƒ½åŠ›åŸŸåˆ†æã€‘è¯¥Benchmarkä¸»è¦è¯„æµ‹...(200å­—)\nã€é£é™©åŸŸåˆ†æã€‘å®‰å…¨æ€§æ–¹é¢...(150å­—)\nã€è¿è¥åŸŸåˆ†æã€‘é¡¹ç›®æ´»è·ƒåº¦...(150å­—)\nã€ç»¼åˆå»ºè®®ã€‘é€‚åˆç”¨äº...(100å­—)"
}}
```

**è¯„åˆ†åŸåˆ™**:
- èƒ½åŠ›åŸŸï¼šä»Agentè¯„æµ‹è§’åº¦åˆ¤æ–­ï¼Œéä¼ ç»ŸNLPä»»åŠ¡æ ‡å‡†
- é£é™©åŸŸï¼šä¸¥æ ¼è¯„ä¼°ï¼Œå®å¯ä¿å®ˆï¼Œå‘ç°ä»»ä½•å®‰å…¨éšæ‚£ç«‹å³æ‰£åˆ†
- è¿è¥åŸŸï¼šæ²¿ç”¨ç°æœ‰æ ‡å‡†ï¼Œå…³æ³¨é•¿æœŸå¯ç»´æŠ¤æ€§

**reasoningè¦æ±‚**:
- æœ€å°‘500å­—ï¼Œåˆ†4ä¸ªéƒ¨åˆ†
- å¿…é¡»å¼•ç”¨å…·ä½“æ•°æ®ï¼ˆstarsæ•°é‡ã€æ›´æ–°æ—¶é—´ã€æ–‡æ¡£è´¨é‡ï¼‰
- ç¦æ­¢æ¨¡ç³Šæè¿°ï¼ˆ"è¾ƒé«˜"â†’"1,500 stars"ï¼‰
"""
```

#### 1.4 æ›´æ–°è¯„åˆ†è®¡ç®—é€»è¾‘

**æ–‡ä»¶**: `src/scorer/llm_scorer.py`

åœ¨ `score` æ–¹æ³•ä¸­ï¼Œæ›¿æ¢æ€»åˆ†è®¡ç®—ï¼š

```python
async def score(self, candidate: RawCandidate) -> ScoredCandidate:
    """ä¸‰åŸŸè¯„åˆ†å®ç°"""
    cached = await self._get_cached_score(candidate)
    if cached:
        scores = cached
    else:
        if not self.client:
            logger.warning("OpenAIæœªé…ç½®,ä½¿ç”¨è§„åˆ™å…œåº•è¯„åˆ†")
            scores = self._fallback_score(candidate)
        else:
            try:
                scores = await self._call_llm(candidate)
            except Exception as exc:
                logger.error("LLMè¯„åˆ†å¤±è´¥,ä½¿ç”¨å…œåº•: %s", exc)
                scores = self._fallback_score(candidate)
            else:
                await self._set_cached_score(candidate, scores)

    # è§£æä¸‰åŸŸè¯„åˆ†
    capability_scores = AgentCapabilityScores(**scores.get("capability_scores", {}))
    risk_scores = RiskDomainScores(**scores.get("risk_scores", {}))
    operational_scores = OperationalScores(**scores.get("operational_scores", {}))

    # è®¡ç®—ä¸‰åŸŸæ€»åˆ†
    capability_total = (
        capability_scores.planning_score * constants.CAPABILITY_WEIGHTS["planning"] +
        capability_scores.tool_use_score * constants.CAPABILITY_WEIGHTS["tool_use"] +
        capability_scores.memory_score * constants.CAPABILITY_WEIGHTS["memory"] +
        capability_scores.collaboration_score * constants.CAPABILITY_WEIGHTS["collaboration"] +
        capability_scores.reasoning_score * constants.CAPABILITY_WEIGHTS["reasoning"]
    )

    risk_total = (
        risk_scores.security_score * constants.RISK_WEIGHTS["security"] +
        risk_scores.robustness_score * constants.RISK_WEIGHTS["robustness"] +
        risk_scores.hallucination_risk * constants.RISK_WEIGHTS["hallucination_risk"] +
        risk_scores.compliance_score * constants.RISK_WEIGHTS["compliance"]
    )

    operational_total = (
        operational_scores.activity_score * constants.SCORE_WEIGHTS["activity"] +
        operational_scores.reproducibility_score * constants.SCORE_WEIGHTS["reproducibility"] +
        operational_scores.license_score * constants.SCORE_WEIGHTS["license"] +
        operational_scores.novelty_score * constants.SCORE_WEIGHTS["novelty"] +
        operational_scores.relevance_score * constants.SCORE_WEIGHTS["relevance"]
    )

    # ç»¼åˆæ€»åˆ†
    total_score = (
        capability_total * constants.SCORE_WEIGHTS_V2["capability_domain"] +
        risk_total * constants.SCORE_WEIGHTS_V2["risk_domain"] +
        operational_total * constants.SCORE_WEIGHTS_V2["operational_domain"]
    )

    # åˆ¤å®šé£é™©ç­‰çº§
    if risk_total < constants.RISK_CRITICAL_THRESHOLD:
        risk_level = "critical"
    elif risk_total < constants.RISK_HIGH_THRESHOLD:
        risk_level = "high"
    elif risk_total < constants.RISK_MODERATE_THRESHOLD:
        risk_level = "moderate"
    else:
        risk_level = "safe"

    # åˆ¤å®šä¼˜å…ˆçº§ï¼ˆèƒ½åŠ›é«˜ + é£é™©ä½ = é«˜ä¼˜å…ˆçº§ï¼‰
    if total_score >= constants.PRIORITY_HIGH_THRESHOLD_V2 and risk_level in ["safe", "moderate"]:
        priority = "high"
    elif total_score >= constants.PRIORITY_MEDIUM_THRESHOLD_V2:
        priority = "medium"
    else:
        priority = "low"

    return ScoredCandidate(
        **candidate.dict(),
        capability_scores=capability_scores,
        risk_scores=risk_scores,
        operational_scores=operational_scores,
        capability_total=capability_total,
        risk_total=risk_total,
        operational_total=operational_total,
        total_score=total_score,
        priority=priority,
        risk_level=risk_level,
        reasoning=scores.get("reasoning", ""),
        last_evaluated_at=datetime.now(),
        evaluation_version="v2.0"
    )
```

---

### Task 2: å¼•å…¥è‡ªè¿›åŒ–æ ·æœ¬æ± 

#### 2.1 åˆ›å»ºæ ·æœ¬ç”Ÿæˆå™¨

**æ–°æ–‡ä»¶**: `src/scorer/prompt_evolution.py`

```python
"""Promptè‡ªè¿›åŒ–æ¨¡å— - åŸºäºBenchmark Self-Evolvingæ€æƒ³"""
from __future__ import annotations

import logging
from typing import List, Dict
from openai import AsyncOpenAI

from src.common import constants
from src.models import RawCandidate

logger = logging.getLogger(__name__)

class PromptEvolutionEngine:
    """æç¤ºè¯è‡ªè¿›åŒ–å¼•æ“"""

    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=constants.OPENAI_API_KEY,
            base_url=constants.OPENAI_BASE_URL
        )

    async def generate_evolved_scenarios(
        self,
        high_confidence_candidates: List[RawCandidate],
        num_variations: int = 3
    ) -> List[Dict[str, str]]:
        """
        åŸºäºé«˜ç½®ä¿¡å€™é€‰ç”Ÿæˆæ¼”åŒ–æƒ…å¢ƒ

        Args:
            high_confidence_candidates: è¯„åˆ†>8.5çš„é«˜è´¨é‡å€™é€‰
            num_variations: æ¯ä¸ªå€™é€‰ç”Ÿæˆçš„å˜ä½“æ•°é‡

        Returns:
            æ¼”åŒ–åçš„è¯„æµ‹æƒ…å¢ƒåˆ—è¡¨
        """
        evolved_scenarios = []

        for candidate in high_confidence_candidates[:5]:  # é™åˆ¶å‰5ä¸ªé«˜è´¨é‡å€™é€‰
            prompt = self._build_evolution_prompt(candidate)

            response = await self.client.chat.completions.create(
                model=constants.LLM_MODEL,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯Benchmarkæ¼”åŒ–ä¸“å®¶"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,  # æé«˜åˆ›é€ æ€§
                n=num_variations,
                max_tokens=800
            )

            for choice in response.choices:
                evolved_scenarios.append({
                    "original_title": candidate.title,
                    "evolved_scenario": choice.message.content,
                    "source": "self-evolution"
                })

        logger.info(f"ç”Ÿæˆ{len(evolved_scenarios)}ä¸ªæ¼”åŒ–æƒ…å¢ƒ")
        return evolved_scenarios

    def _build_evolution_prompt(self, candidate: RawCandidate) -> str:
        """æ„å»ºæ¼”åŒ–prompt"""
        return f"""åŸºäºä»¥ä¸‹é«˜è´¨é‡Benchmarkï¼Œç”Ÿæˆ3ä¸ªæ¼”åŒ–å˜ä½“ï¼š

åŸå§‹Benchmark:
- æ ‡é¢˜: {candidate.title}
- æ‘˜è¦: {candidate.abstract[:300]}

æ¼”åŒ–è¦æ±‚:
1. **é«˜ç½®ä¿¡é‡è¿°**: ä¿ç•™æ ¸å¿ƒè¯„æµ‹ç›®æ ‡ï¼Œæ¢ç”¨ä¸åŒè¡¨è¿°
2. **æƒ…å¢ƒæ‰©å±•**: å¢åŠ æ–°çš„è¯„æµ‹ç»´åº¦ï¼ˆå¦‚æ—¶é—´çº¦æŸã€å¤šæ¨¡æ€ï¼‰
3. **éš¾åº¦æå‡**: å¼•å…¥æ›´å¤æ‚çš„åœºæ™¯ï¼ˆå¦‚å¯¹æŠ—æ ·æœ¬ã€é•¿æœŸè®°å¿†ï¼‰

è¾“å‡ºæ ¼å¼:
1. [å˜ä½“1æè¿°]
2. [å˜ä½“2æè¿°]
3. [å˜ä½“3æè¿°]
"""
```

#### 2.2 é›†æˆåˆ°ä¸»æµç¨‹

**æ–‡ä»¶**: `src/main.py`

åœ¨ä¸»æµç¨‹ä¸­ï¼Œå®šæœŸæ‰§è¡Œè‡ªè¿›åŒ–ï¼š

```python
async def run_self_evolution(scored_candidates: List[ScoredCandidate]):
    """è¿è¡Œè‡ªè¿›åŒ–æµç¨‹"""
    from src.scorer.prompt_evolution import PromptEvolutionEngine

    # ç­›é€‰é«˜è´¨é‡å€™é€‰
    high_quality = [c for c in scored_candidates if c.total_score >= 8.5]

    if len(high_quality) < 3:
        logger.info("é«˜è´¨é‡å€™é€‰ä¸è¶³3ä¸ªï¼Œè·³è¿‡è‡ªè¿›åŒ–")
        return

    engine = PromptEvolutionEngine()
    evolved_scenarios = await engine.generate_evolved_scenarios(high_quality)

    # ä¿å­˜æ¼”åŒ–ç»“æœåˆ°æœ¬åœ°
    import json
    with open("data/evolved_scenarios.json", "w", encoding="utf-8") as f:
        json.dump(evolved_scenarios, f, ensure_ascii=False, indent=2)

    logger.info(f"âœ… è‡ªè¿›åŒ–å®Œæˆï¼Œç”Ÿæˆ{len(evolved_scenarios)}ä¸ªæ–°æƒ…å¢ƒ")
```

---

### Task 3: å®‰å…¨/å¯æ§å›è·¯

#### 3.1 åˆ›å»ºå®‰å…¨è¯„ä¼°æ¨¡å—

**æ–°æ–‡ä»¶**: `src/scorer/security_validator.py`

```python
"""å®‰å…¨éªŒè¯æ¨¡å— - åŸºäºRAS-Evalæ€æƒ³"""
from __future__ import annotations

import logging
import re
from typing import List, Dict, Tuple
from openai import AsyncOpenAI

from src.common import constants
from src.models import ScoredCandidate

logger = logging.getLogger(__name__)

class SecurityValidator:
    """å®‰å…¨éªŒè¯å™¨"""

    # CWEå¸¸è§æ¼æ´æ¨¡å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰
    SECURITY_PATTERNS = {
        "command_injection": r"(os\.system|subprocess\.call|eval\()",
        "sql_injection": r"(SELECT.*FROM.*WHERE|INSERT INTO)",
        "xss": r"(<script|javascript:|onerror=)",
        "path_traversal": r"\.\./",
        "hardcoded_secret": r"(password|api_key|secret)\s*=\s*['\"][^'\"]+['\"]"
    }

    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=constants.OPENAI_API_KEY,
            base_url=constants.OPENAI_BASE_URL
        )

    async def validate_candidate(
        self,
        candidate: ScoredCandidate
    ) -> Tuple[bool, List[str]]:
        """
        éªŒè¯å€™é€‰å®‰å…¨æ€§

        Returns:
            (is_safe, warnings) - æ˜¯å¦å®‰å…¨ + è­¦å‘Šåˆ—è¡¨
        """
        warnings = []

        # 1. é™æ€æ¨¡å¼æ£€æµ‹ï¼ˆåŸºäºæ­£åˆ™ï¼‰
        if candidate.github_url:
            pattern_warnings = self._detect_security_patterns(candidate)
            warnings.extend(pattern_warnings)

        # 2. LLMè‡ªæˆ‘è¯„ä¼°ï¼ˆå¯¹æŠ—æ€§æç¤ºï¼‰
        llm_warnings = await self._llm_security_check(candidate)
        warnings.extend(llm_warnings)

        # 3. é£é™©è¯„åˆ†äºŒæ¬¡éªŒè¯
        if candidate.risk_scores and candidate.risk_scores.security_score < 5.0:
            warnings.append(f"é£é™©è¯„åˆ†è¿‡ä½: security_score={candidate.risk_scores.security_score}")

        is_safe = len(warnings) == 0
        return is_safe, warnings

    def _detect_security_patterns(self, candidate: ScoredCandidate) -> List[str]:
        """é™æ€æ¨¡å¼æ£€æµ‹"""
        warnings = []
        text = f"{candidate.title} {candidate.abstract or ''} {candidate.reasoning}"

        for pattern_name, regex in self.SECURITY_PATTERNS.items():
            if re.search(regex, text, re.IGNORECASE):
                warnings.append(f"æ£€æµ‹åˆ°æ½œåœ¨å®‰å…¨æ¨¡å¼: {pattern_name}")

        return warnings

    async def _llm_security_check(self, candidate: ScoredCandidate) -> List[str]:
        """LLMå¯¹æŠ—æ€§å®‰å…¨æ£€æŸ¥"""
        prompt = f"""ä»¥å®‰å…¨å®¡è®¡ä¸“å®¶èº«ä»½ï¼Œæ£€æŸ¥ä»¥ä¸‹Benchmarkå€™é€‰çš„å®‰å…¨é£é™©ï¼š

æ ‡é¢˜: {candidate.title}
æ¥æº: {candidate.source}
URL: {candidate.url}
æ‘˜è¦: {candidate.abstract[:500]}

è¯·æ£€æŸ¥ä»¥ä¸‹å®‰å…¨é£é™©ï¼š
1. æ˜¯å¦åŒ…å«æ¶æ„ä»£ç æˆ–åé—¨ï¼Ÿ
2. æ•°æ®é›†æ˜¯å¦å­˜åœ¨éšç§æ³„éœ²é£é™©ï¼Ÿ
3. æ˜¯å¦æœ‰æœªæˆæƒçš„å¤–éƒ¨è°ƒç”¨ï¼Ÿ
4. Licenseæ˜¯å¦å­˜åœ¨æ³•å¾‹é£é™©ï¼Ÿ
5. æ˜¯å¦å­˜åœ¨å·²çŸ¥çš„CVEæ¼æ´ï¼Ÿ

è¾“å‡ºæ ¼å¼ï¼ˆä»…è¿”å›å‘ç°çš„é—®é¢˜ï¼Œæ— é—®é¢˜è¿”å›"SAFE"ï¼‰:
[é£é™©ç±»å‹]: [å…·ä½“æè¿°]
"""

        response = await self.client.chat.completions.create(
            model=constants.LLM_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ç½‘ç»œå®‰å…¨ä¸“å®¶ï¼Œä¸“æ³¨æ¼æ´æ£€æµ‹"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,  # ä½æ¸©åº¦ï¼Œä¿æŒä¸¥è°¨
            max_tokens=500
        )

        result = response.choices[0].message.content or ""

        if "SAFE" in result.upper():
            return []
        else:
            # è§£æé£é™©é¡¹
            warnings = [line.strip() for line in result.split("\n") if line.strip()]
            return warnings
```

#### 3.2 é›†æˆåˆ°å­˜å‚¨å‰éªŒè¯

**æ–‡ä»¶**: `src/main.py`

åœ¨å­˜å‚¨å‰å¢åŠ å®‰å…¨å›è·¯ï¼š

```python
async def security_validation_loop(candidates: List[ScoredCandidate]) -> List[ScoredCandidate]:
    """å®‰å…¨éªŒè¯å¾ªç¯"""
    from src.scorer.security_validator import SecurityValidator

    validator = SecurityValidator()
    safe_candidates = []
    rejected_candidates = []

    for candidate in candidates:
        is_safe, warnings = await validator.validate_candidate(candidate)

        if is_safe:
            safe_candidates.append(candidate)
        else:
            logger.warning(
                f"å€™é€‰è¢«å®‰å…¨æ‹’ç»: {candidate.title[:50]}\n"
                f"åŸå› : {'; '.join(warnings)}"
            )
            rejected_candidates.append((candidate, warnings))

    # è®°å½•è¢«æ‹’ç»çš„å€™é€‰
    if rejected_candidates:
        import json
        with open("logs/security_rejected.json", "w", encoding="utf-8") as f:
            json.dump([
                {
                    "title": c.title,
                    "url": c.url,
                    "warnings": w
                }
                for c, w in rejected_candidates
            ], f, ensure_ascii=False, indent=2)

    logger.info(
        f"âœ… å®‰å…¨éªŒè¯å®Œæˆ: é€šè¿‡{len(safe_candidates)}, "
        f"æ‹’ç»{len(rejected_candidates)}"
    )

    return safe_candidates
```

---

### Task 4: æŒç»­å­¦ä¹ æ ¡éªŒ

#### 4.1 åˆ›å»ºå¤æµ‹è°ƒåº¦å™¨

**æ–°æ–‡ä»¶**: `src/tracker/rescore_scheduler.py`

```python
"""å¤æµ‹è°ƒåº¦å™¨ - åŸºäºLifelongAgentBenchæ€æƒ³"""
from __future__ import annotations

import logging
from datetime import datetime, timedelta
from typing import List

from src.storage.feishu_storage import FeishuStorage
from src.scorer.llm_scorer import LLMScorer
from src.models import RawCandidate, ScoredCandidate

logger = logging.getLogger(__name__)

class RescoreScheduler:
    """å®šæœŸå¤æµ‹è°ƒåº¦å™¨"""

    RESCORE_INTERVAL_DAYS = 14  # æ¯14å¤©å¤æµ‹ä¸€æ¬¡

    def __init__(self):
        self.storage = FeishuStorage()
        self.scorer = LLMScorer()

    async def run_rescore(self):
        """æ‰§è¡Œå¤æµ‹ä»»åŠ¡"""
        # 1. ä»é£ä¹¦è¡¨æ ¼è·å–éœ€è¦å¤æµ‹çš„å€™é€‰
        candidates_to_rescore = await self._get_candidates_for_rescore()

        if not candidates_to_rescore:
            logger.info("æ— éœ€å¤æµ‹çš„å€™é€‰")
            return

        logger.info(f"å¼€å§‹å¤æµ‹ {len(candidates_to_rescore)} ä¸ªå€™é€‰")

        # 2. é‡æ–°è¯„åˆ†
        async with self.scorer:
            rescored = []
            for old_candidate in candidates_to_rescore:
                # è½¬æ¢ä¸ºRawCandidate
                raw = self._convert_to_raw(old_candidate)

                # é‡æ–°è¯„åˆ†
                new_scored = await self.scorer.score(raw)

                # è®¡ç®—åˆ†æ•°æ¼‚ç§»
                score_drift = new_scored.total_score - old_candidate["total_score"]

                rescored.append({
                    "title": new_scored.title,
                    "old_score": old_candidate["total_score"],
                    "new_score": new_scored.total_score,
                    "drift": score_drift,
                    "risk_level": new_scored.risk_level
                })

                # 3. æ›´æ–°é£ä¹¦è¡¨æ ¼
                await self.storage.update_score(
                    record_id=old_candidate["record_id"],
                    new_scores=new_scored
                )

                # 4. å¦‚æœåˆ†æ•°ä¸‹é™è¶…è¿‡2åˆ†ï¼Œå‘é€å‘Šè­¦
                if score_drift < -2.0:
                    logger.warning(
                        f"âš ï¸ å€™é€‰è´¨é‡ä¸‹é™: {new_scored.title[:50]}\n"
                        f"åˆ†æ•°å˜åŒ–: {old_candidate['total_score']:.1f} â†’ "
                        f"{new_scored.total_score:.1f} ({score_drift:+.1f})"
                    )

        # 5. ç”Ÿæˆå¤æµ‹æŠ¥å‘Š
        self._generate_rescore_report(rescored)

    async def _get_candidates_for_rescore(self) -> List[dict]:
        """è·å–éœ€è¦å¤æµ‹çš„å€™é€‰"""
        # ä»é£ä¹¦è¡¨æ ¼æŸ¥è¯¢ last_evaluated_at è·ä»Šè¶…è¿‡14å¤©çš„è®°å½•
        # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…éœ€è¦è°ƒç”¨é£ä¹¦API
        cutoff_date = datetime.now() - timedelta(days=self.RESCORE_INTERVAL_DAYS)

        # TODO: å®ç°é£ä¹¦APIæŸ¥è¯¢
        # candidates = await self.storage.query_old_evaluations(cutoff_date)

        return []

    def _convert_to_raw(self, feishu_record: dict) -> RawCandidate:
        """å°†é£ä¹¦è®°å½•è½¬æ¢ä¸ºRawCandidate"""
        return RawCandidate(
            title=feishu_record["title"],
            url=feishu_record["url"],
            source=feishu_record["source"],
            abstract=feishu_record.get("abstract", ""),
            # ... å…¶ä»–å­—æ®µ
        )

    def _generate_rescore_report(self, rescored: List[dict]):
        """ç”Ÿæˆå¤æµ‹æŠ¥å‘Š"""
        import json

        report_path = f"logs/rescore_report_{datetime.now():%Y%m%d}.json"
        with open(report_path, "w", encoding="utf-8") as f:
            json.dump({
                "timestamp": datetime.now().isoformat(),
                "total_rescored": len(rescored),
                "significant_changes": [
                    r for r in rescored if abs(r["drift"]) > 1.0
                ],
                "details": rescored
            }, f, ensure_ascii=False, indent=2)

        logger.info(f"âœ… å¤æµ‹æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
```

#### 4.2 æ·»åŠ GitHub Actionså®šæ—¶ä»»åŠ¡

**æ–°æ–‡ä»¶**: `.github/workflows/rescore_candidates.yml`

```yaml
name: BenchScope Rescore Scheduler

on:
  schedule:
    - cron: '0 10 */14 * *'  # æ¯14å¤©çš„10:00è¿è¡Œ
  workflow_dispatch:

jobs:
  rescore:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run rescore scheduler
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          FEISHU_APP_ID: ${{ secrets.FEISHU_APP_ID }}
          FEISHU_APP_SECRET: ${{ secrets.FEISHU_APP_SECRET }}
        run: |
          python -c "
          import asyncio
          from src.tracker.rescore_scheduler import RescoreScheduler

          async def main():
              scheduler = RescoreScheduler()
              await scheduler.run_rescore()

          asyncio.run(main())
          "

      - name: Upload rescore report
        uses: actions/upload-artifact@v4
        with:
          name: rescore-report
          path: logs/rescore_report_*.json
          retention-days: 30
```

---

### Task 5: ä¿¡æ¯æŠ½å–åŒè½¨åˆ¶

#### 5.1 åˆ›å»ºä¼ ç»Ÿè§£æå™¨

**æ–°æ–‡ä»¶**: `src/collectors/fallback_extractor.py`

```python
"""ä¼ ç»Ÿè§£æå™¨ - ä½œä¸ºLLMæŠ½å–çš„æ ¡éªŒ"""
from __future__ import annotations

import re
import logging
from typing import Optional, Dict
from bs4 import BeautifulSoup
import httpx

logger = logging.getLogger(__name__)

class FallbackExtractor:
    """è§„åˆ™è§£æå™¨ï¼ˆä¼ ç»Ÿæ–¹æ³•ï¼‰"""

    @staticmethod
    async def extract_arxiv_metadata(arxiv_url: str) -> Dict[str, Optional[str]]:
        """ä»arXiv URLæå–å…ƒæ•°æ®"""
        # æå–arXiv ID
        match = re.search(r"arxiv\.org/abs/(\d+\.\d+)", arxiv_url)
        if not match:
            return {}

        arxiv_id = match.group(1)

        # è°ƒç”¨arXiv API
        api_url = f"http://export.arxiv.org/api/query?id_list={arxiv_id}"

        async with httpx.AsyncClient() as client:
            resp = await client.get(api_url, timeout=10)
            soup = BeautifulSoup(resp.text, "xml")

            entry = soup.find("entry")
            if not entry:
                return {}

            return {
                "title": entry.find("title").text.strip() if entry.find("title") else None,
                "abstract": entry.find("summary").text.strip() if entry.find("summary") else None,
                "published_date": entry.find("published").text[:10] if entry.find("published") else None,
                "authors": [
                    author.find("name").text
                    for author in entry.find_all("author")
                ] if entry.find_all("author") else None
            }

    @staticmethod
    async def extract_github_metadata(github_url: str) -> Dict[str, Optional[str]]:
        """ä»GitHub URLæå–å…ƒæ•°æ®"""
        # æå–owner/repo
        match = re.search(r"github\.com/([^/]+)/([^/]+)", github_url)
        if not match:
            return {}

        owner, repo = match.groups()

        # è°ƒç”¨GitHub API
        api_url = f"https://api.github.com/repos/{owner}/{repo}"

        async with httpx.AsyncClient() as client:
            resp = await client.get(
                api_url,
                headers={"Accept": "application/vnd.github+json"},
                timeout=10
            )

            if resp.status_code != 200:
                return {}

            data = resp.json()

            return {
                "title": data.get("full_name"),
                "abstract": data.get("description"),
                "stars": data.get("stargazers_count"),
                "license": data.get("license", {}).get("spdx_id") if data.get("license") else None,
                "updated_at": data.get("updated_at", "")[:10]
            }

class ConsistencyChecker:
    """ä¸€è‡´æ€§æ£€æŸ¥å™¨"""

    @staticmethod
    def check_consistency(
        llm_extracted: Dict,
        fallback_extracted: Dict,
        threshold: float = 0.8
    ) -> Dict[str, bool]:
        """æ£€æŸ¥LLMæŠ½å–ä¸ä¼ ç»ŸæŠ½å–çš„ä¸€è‡´æ€§"""
        results = {}

        # æ ‡é¢˜ä¸€è‡´æ€§ï¼ˆä½¿ç”¨ç¼–è¾‘è·ç¦»ï¼‰
        if "title" in llm_extracted and "title" in fallback_extracted:
            similarity = ConsistencyChecker._string_similarity(
                llm_extracted["title"],
                fallback_extracted["title"]
            )
            results["title_consistent"] = similarity >= threshold

        # æ—¥æœŸä¸€è‡´æ€§ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
        if "published_date" in llm_extracted and "published_date" in fallback_extracted:
            results["date_consistent"] = (
                llm_extracted["published_date"] == fallback_extracted["published_date"]
            )

        # Starsä¸€è‡´æ€§ï¼ˆè¯¯å·®<10%ï¼‰
        if "stars" in llm_extracted and "stars" in fallback_extracted:
            llm_stars = int(llm_extracted.get("stars", 0) or 0)
            fb_stars = int(fallback_extracted.get("stars", 0) or 0)

            if fb_stars > 0:
                error_rate = abs(llm_stars - fb_stars) / fb_stars
                results["stars_consistent"] = error_rate < 0.1

        return results

    @staticmethod
    def _string_similarity(s1: str, s2: str) -> float:
        """è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ï¼ˆç®€åŒ–ç‰ˆLevenshteinï¼‰"""
        if not s1 or not s2:
            return 0.0

        # ç®€åŒ–ï¼šè®¡ç®—å…±åŒè¯æ±‡å æ¯”
        words1 = set(s1.lower().split())
        words2 = set(s2.lower().split())

        intersection = words1 & words2
        union = words1 | words2

        return len(intersection) / len(union) if union else 0.0
```

#### 5.2 é›†æˆåˆ°é‡‡é›†æµç¨‹

**æ–‡ä»¶**: `src/collectors/arxiv_collector.py`

åœ¨é‡‡é›†åå¢åŠ ä¸€è‡´æ€§æ ¡éªŒï¼š

```python
async def collect_with_validation(self) -> List[RawCandidate]:
    """é‡‡é›† + ä¸€è‡´æ€§æ ¡éªŒ"""
    from src.collectors.fallback_extractor import FallbackExtractor, ConsistencyChecker

    # 1. åŸæœ‰é‡‡é›†æµç¨‹
    candidates = await self.collect()

    # 2. å¯¹å‰10ä¸ªå€™é€‰è¿›è¡Œä¸€è‡´æ€§æ ¡éªŒ
    validated = []
    extractor = FallbackExtractor()
    checker = ConsistencyChecker()

    for candidate in candidates[:10]:
        # LLMå·²æŠ½å–çš„æ•°æ®
        llm_data = {
            "title": candidate.title,
            "abstract": candidate.abstract,
            "published_date": candidate.publish_date
        }

        # ä¼ ç»Ÿæ–¹æ³•æŠ½å–
        fallback_data = await extractor.extract_arxiv_metadata(candidate.url)

        # ä¸€è‡´æ€§æ£€æŸ¥
        consistency = checker.check_consistency(llm_data, fallback_data)

        if all(consistency.values()):
            validated.append(candidate)
        else:
            logger.warning(
                f"âš ï¸ ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {candidate.title[:50]}\n"
                f"ä¸ä¸€è‡´å­—æ®µ: {[k for k, v in consistency.items() if not v]}"
            )

    logger.info(f"ä¸€è‡´æ€§éªŒè¯: {len(validated)}/{len(candidates[:10])} é€šè¿‡")

    return candidates  # è¿”å›å…¨éƒ¨ï¼Œä½†è®°å½•ä¸ä¸€è‡´çš„
```

---

## å››ã€é£ä¹¦è¡¨æ ¼å­—æ®µæ›´æ–°

### 4.1 æ–°å¢å­—æ®µæ¸…å•

åœ¨é£ä¹¦å¤šç»´è¡¨æ ¼ä¸­æ–°å¢ä»¥ä¸‹å­—æ®µï¼ˆæ‰§è¡Œè„šæœ¬ `scripts/create_feishu_fields_v2.py`ï¼‰ï¼š

**èƒ½åŠ›åŸŸå­—æ®µ** (5ä¸ª):
- `planning_score` (æ•°å­—ï¼Œ0-10)
- `tool_use_score` (æ•°å­—ï¼Œ0-10)
- `memory_score` (æ•°å­—ï¼Œ0-10)
- `collaboration_score` (æ•°å­—ï¼Œ0-10)
- `reasoning_score` (æ•°å­—ï¼Œ0-10)

**é£é™©åŸŸå­—æ®µ** (5ä¸ª):
- `security_score` (æ•°å­—ï¼Œ0-10)
- `robustness_score` (æ•°å­—ï¼Œ0-10)
- `hallucination_risk` (æ•°å­—ï¼Œ0-10)
- `compliance_score` (æ•°å­—ï¼Œ0-10)
- `risk_level` (å•é€‰ï¼šsafe/moderate/high/critical)

**å…ƒæ•°æ®å­—æ®µ** (3ä¸ª):
- `capability_total` (æ•°å­—ï¼Œèƒ½åŠ›åŸŸæ€»åˆ†)
- `risk_total` (æ•°å­—ï¼Œé£é™©åŸŸæ€»åˆ†)
- `operational_total` (æ•°å­—ï¼Œè¿è¥åŸŸæ€»åˆ†)
- `last_evaluated_at` (æ—¥æœŸæ—¶é—´)
- `evaluation_version` (æ–‡æœ¬ï¼Œå¦‚"v2.0")

### 4.2 é£ä¹¦é€šçŸ¥å¡ç‰‡æ›´æ–°

**æ–‡ä»¶**: `src/notifier/feishu_notifier.py`

æ›´æ–°å¡ç‰‡å†…å®¹ï¼Œå±•ç¤ºä¸‰åŸŸè¯„åˆ†ï¼š

```python
def _build_card(self, title: str, candidate: ScoredCandidate) -> dict:
    """æ„å»ºé«˜ä¼˜å…ˆçº§å€™é€‰å¡ç‰‡ - ä¸‰åŸŸè¯„åˆ†ç‰ˆ"""

    content = (
        f"**{candidate.title[:constants.TITLE_TRUNCATE_LONG]}**\n\n"
        f"ç»¼åˆè¯„åˆ†: **{candidate.total_score:.1f}** / 10  |  "
        f"ä¼˜å…ˆçº§: **{priority_label}**  |  "
        f"é£é™©: **{candidate.risk_level}**\n\n"

        "**èƒ½åŠ›åŸŸ** (æ€»åˆ†: {candidate.capability_total:.1f})\n"
        f"è§„åˆ’ {candidate.capability_scores.planning_score:.1f}  |  "
        f"å·¥å…· {candidate.capability_scores.tool_use_score:.1f}  |  "
        f"è®°å¿† {candidate.capability_scores.memory_score:.1f}  |  "
        f"åä½œ {candidate.capability_scores.collaboration_score:.1f}  |  "
        f"æ¨ç† {candidate.capability_scores.reasoning_score:.1f}\n\n"

        "**é£é™©åŸŸ** (æ€»åˆ†: {candidate.risk_total:.1f})\n"
        f"å®‰å…¨ {candidate.risk_scores.security_score:.1f}  |  "
        f"é²æ£’ {candidate.risk_scores.robustness_score:.1f}  |  "
        f"å¹»è§‰ {candidate.risk_scores.hallucination_risk:.1f}  |  "
        f"åˆè§„ {candidate.risk_scores.compliance_score:.1f}\n\n"

        "**è¿è¥åŸŸ** (æ€»åˆ†: {candidate.operational_total:.1f})\n"
        f"æ´»è·ƒ {candidate.operational_scores.activity_score:.1f}  |  "
        f"å¤ç° {candidate.operational_scores.reproducibility_score:.1f}  |  "
        f"è®¸å¯ {candidate.operational_scores.license_score:.1f}  |  "
        f"æ–°é¢– {candidate.operational_scores.novelty_score:.1f}  |  "
        f"é€‚é… {candidate.operational_scores.relevance_score:.1f}\n\n"

        f"**æ¥æº**: {source_name}\n\n"
        f"**è¯„åˆ†ä¾æ®**\n{candidate.reasoning}"
    )

    # ... å…¶ä½™å¡ç‰‡ç»“æ„ä¿æŒä¸å˜
```

---

## äº”ã€æµ‹è¯•ä¸éªŒæ”¶

### 5.1 å•å…ƒæµ‹è¯•

**æ–°æ–‡ä»¶**: `tests/test_three_domain_scoring.py`

```python
"""ä¸‰åŸŸè¯„åˆ†æµ‹è¯•"""
import pytest
from src.scorer.llm_scorer import LLMScorer
from src.models import RawCandidate

@pytest.mark.asyncio
async def test_three_domain_scoring():
    """æµ‹è¯•ä¸‰åŸŸè¯„åˆ†åŠŸèƒ½"""
    scorer = LLMScorer()

    # åˆ›å»ºæµ‹è¯•å€™é€‰
    candidate = RawCandidate(
        title="WebArena: A Realistic Web Environment for Building Autonomous Agents",
        url="https://arxiv.org/abs/2307.13854",
        source="arxiv",
        abstract="A benchmark for web-based agent tasks..."
    )

    async with scorer:
        scored = await scorer.score(candidate)

    # éªŒè¯ä¸‰åŸŸè¯„åˆ†å­˜åœ¨
    assert scored.capability_scores is not None
    assert scored.risk_scores is not None
    assert scored.operational_scores is not None

    # éªŒè¯æ€»åˆ†è®¡ç®—
    assert scored.capability_total > 0
    assert scored.risk_total > 0
    assert scored.operational_total > 0

    # éªŒè¯é£é™©ç­‰çº§
    assert scored.risk_level in ["safe", "moderate", "high", "critical"]

    # éªŒè¯ä¼˜å…ˆçº§
    assert scored.priority in ["high", "medium", "low"]
```

### 5.2 é›†æˆæµ‹è¯•

**æµ‹è¯•æ­¥éª¤**:

1. **è¿è¡Œå®Œæ•´æµç¨‹**:
```bash
uv run python src/main.py
```

2. **æ£€æŸ¥é£ä¹¦è¡¨æ ¼**:
- éªŒè¯æ–°å¢çš„èƒ½åŠ›åŸŸ/é£é™©åŸŸå­—æ®µæ˜¯å¦æ­£ç¡®å¡«å……
- ç¡®è®¤ `risk_level` å’Œ `evaluation_version` å­—æ®µ

3. **éªŒè¯å®‰å…¨å›è·¯**:
```bash
uv run python -c "
import asyncio
from src.scorer.security_validator import SecurityValidator
from src.models import ScoredCandidate

async def test():
    validator = SecurityValidator()
    # åˆ›å»ºæµ‹è¯•å€™é€‰...
    is_safe, warnings = await validator.validate_candidate(candidate)
    print(f'å®‰å…¨: {is_safe}, è­¦å‘Š: {warnings}')

asyncio.run(test())
"
```

4. **éªŒè¯å¤æµ‹è°ƒåº¦**:
```bash
# æ‰‹åŠ¨è§¦å‘å¤æµ‹
uv run python -c "
import asyncio
from src.tracker.rescore_scheduler import RescoreScheduler

asyncio.run(RescoreScheduler().run_rescore())
"
```

### 5.3 éªŒï¿½ï¿½æ ‡å‡†

âœ… **åŠŸèƒ½éªŒæ”¶**:
- [ ] ä¸‰åŸŸè¯„åˆ†æ­£ç¡®è®¡ç®—ï¼ˆèƒ½åŠ›/é£é™©/è¿è¥ï¼‰
- [ ] é£é™©ç­‰çº§æ­£ç¡®åˆ¤å®šï¼ˆsafe/moderate/high/criticalï¼‰
- [ ] å®‰å…¨éªŒè¯å™¨èƒ½è¯†åˆ«5ç±»å¸¸è§æ¼æ´
- [ ] å¤æµ‹è°ƒåº¦å™¨æ¯14å¤©è‡ªåŠ¨è¿è¡Œ
- [ ] ä¿¡æ¯æŠ½å–ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡ç‡>80%

âœ… **æ€§èƒ½éªŒæ”¶**:
- [ ] LLMè¯„åˆ†æ—¶é—´<10ç§’/å€™é€‰ï¼ˆmax_tokens=1600ï¼‰
- [ ] å®‰å…¨éªŒè¯å¢åŠ çš„å¼€é”€<20%
- [ ] å¤æµ‹ä»»åŠ¡å®Œæˆæ—¶é—´<30åˆ†é’Ÿï¼ˆ100ä¸ªå€™é€‰ï¼‰

âœ… **æ•°æ®éªŒæ”¶**:
- [ ] é£ä¹¦è¡¨æ ¼æ–°å¢å­—æ®µå…¨éƒ¨æ­£ç¡®åˆ›å»º
- [ ] é£ä¹¦é€šçŸ¥å¡ç‰‡æ­£ç¡®å±•ç¤ºä¸‰åŸŸè¯„åˆ†
- [ ] reasoningå­—æ®µå¹³å‡é•¿åº¦>500å­—ï¼ˆvs æ—§ç‰ˆ200å­—ï¼‰

---

## å…­ã€æ³¨æ„äº‹é¡¹

### âš ï¸ é‡è¦çº¦æŸ

1. **å‘åå…¼å®¹**: æ—§çš„5ç»´è¯„åˆ†æ¨¡å‹ï¼ˆv1.0ï¼‰ä»éœ€æ”¯æŒï¼Œæ–°æ¨¡å‹æ ‡è®°ä¸ºv2.0
2. **æˆæœ¬æ§åˆ¶**: ä¸‰åŸŸè¯„åˆ†tokenæ¶ˆè€—å¢åŠ ~3å€ï¼Œéœ€ç›‘æ§OpenAIè´¹ç”¨
3. **æµ‹è¯•ä¼˜å…ˆ**: æ‰€æœ‰æ–°æ¨¡å—å¿…é¡»å…ˆåœ¨æµ‹è¯•æ•°æ®ä¸ŠéªŒè¯ï¼Œå†ä¸Šçº¿ç”Ÿäº§
4. **é£ä¹¦å­—æ®µ**: åœ¨åˆ›å»ºæ–°å­—æ®µå‰ï¼Œå…ˆåœ¨æµ‹è¯•è¡¨æ ¼éªŒè¯ï¼Œé¿å…æ±¡æŸ“ç”Ÿäº§æ•°æ®

### ğŸ“‹ å®æ–½é¡ºåº

**Phase 7.1** (Week 1-2):
1. Task 1: é‡æ„è¯„åˆ†æ¨¡å‹ï¼ˆæ•°æ®æ¨¡å‹ + LLM prompt + è®¡ç®—é€»è¾‘ï¼‰
2. Task 5: ä¿¡æ¯æŠ½å–åŒè½¨åˆ¶ï¼ˆå…ˆå®ç°ï¼Œç”¨äºæ ¡éªŒæ–°è¯„åˆ†å‡†ç¡®æ€§ï¼‰

**Phase 7.2** (Week 3):
3. Task 3: å®‰å…¨/å¯æ§å›è·¯ï¼ˆåŸºäºæ–°è¯„åˆ†æ¨¡å‹ï¼‰
4. é£ä¹¦å­—æ®µæ›´æ–° + é€šçŸ¥å¡ç‰‡æ”¹ç‰ˆ

**Phase 7.3** (Week 4):
5. Task 4: æŒç»­å­¦ä¹ æ ¡éªŒï¼ˆå¤æµ‹è°ƒåº¦å™¨ï¼‰
6. Task 2: è‡ªè¿›åŒ–æ ·æœ¬æ± ï¼ˆé•¿æœŸè¿è¡Œï¼‰

**Phase 7.4** (Week 5):
7. å…¨é¢æµ‹è¯• + æ€§èƒ½ä¼˜åŒ–
8. æ–‡æ¡£æ›´æ–° + ä¸Šçº¿éƒ¨ç½²

---

## ä¸ƒã€å‚è€ƒæ–‡çŒ®

1. arXiv 2503.16416 - Agentè¯„æµ‹ç»¼è¿°
2. arXiv 2502.15865 - é‡‘èAgenté£é™©è¯„ä¼°
3. arXiv 2506.15253 - RAS-Evalå®‰å…¨è¯„æµ‹
4. arXiv 2505.11942 - LifelongAgentBench
5. aclanthology.org/2025.coling-main.223 - Benchmark Self-Evolving
6. scisimple.com - GPT-4ç§‘å­¦ä¿¡æ¯æŠ½å–è¯„ä¼°

---

**Codexï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§æœ¬æ–‡æ¡£å®æ–½Phase 7æ”¹è¿›ã€‚é‡åˆ°ä¸æ˜ç¡®çš„åœ°æ–¹ï¼Œå…ˆè¯¢é—®å†åŠ¨æ‰‹ã€‚è®°å¾—å•å…ƒæµ‹è¯•å…ˆè¡Œï¼Œæ‰‹åŠ¨æµ‹è¯•å¿…åšã€‚**
